{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from typing import List, Tuple, Dict\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract segregation energies out of csv. file\n",
    "def seg_energies(element: str, data_frame: pd.DataFrame):\n",
    "    segs = []\n",
    "    for i in data_frame.loc[:, element]:\n",
    "        segs.append(i)\n",
    "    return segs\n",
    "\n",
    "# Calculate diffusion coefficient at specific temperature\n",
    "def diff_coef(D0: float, dQ, T, kB: float = (8.314/(1.602*10**(-19)))/(6.022*10**(23))):\n",
    "    return D0*np.exp(-dQ/(kB*T))\n",
    "\n",
    "# Get current temperature\n",
    "def get_temperature(_: int):\n",
    "    return 2000\n",
    "\n",
    "# Get temperature at specific time step, following a linear cooling heat treatment\n",
    "def linear_heat_treatment(T0: float, t_tot: int, Tend: float, t: float):\n",
    "    k = (Tend-T0)/t_tot\n",
    "    T = k*t + T0\n",
    "    return T\n",
    "\n",
    "# Get temperature at specific time step, following a newton cooling heat treatment\n",
    "def newton_cooling(T0: float, t: int, Temb: float, r: float):\n",
    "    T = Temb + (T0-Temb)*np.exp(-r*t**(0.5))\n",
    "    return T\n",
    "\n",
    "# Calculate fraction of GB sites compared to all sites in the system\n",
    "def gb_site_fraction(R_G=100e-6, gb_width=8.4e-10):\n",
    "    V_G = R_G**3\n",
    "    V_GB = V_G - (R_G - gb_width)**3\n",
    "    return V_GB/V_G\n",
    "\n",
    "\n",
    "def get_x_hat(gb_conc: np.ndarray):\n",
    "    return gb_conc\n",
    "\n",
    "def wt_to_at(conc: Dict[str, float]):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    conc : Dict[str, float]\n",
    "            Concentration of individual species given in mass.%.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[float]\n",
    "    Atomic fractions of species in Iron, not at.%.\n",
    "    \"\"\"\n",
    "\n",
    "    Na = 6.022*10**23\n",
    "\n",
    "    masses = {\n",
    "        \"fe\" : 55.845,\n",
    "        \"c\" : 12.011,\n",
    "        \"as\" : 74.922,\n",
    "        \"cr\" : 51.996,\n",
    "        \"ni\" : 58.693,\n",
    "        \"mo\" : 95.95,\n",
    "        \"sb\" : 121.76,\n",
    "        \"sn\" : 118.71\n",
    "    }\n",
    "    total_concentration = 100 - sum(conc.values())  # Rename the sum variable here\n",
    "\n",
    "    fe_atoms = total_concentration * Na / masses[\"fe\"]  # Use the renamed variable\n",
    "\n",
    "    atomic_numbers = {}\n",
    "    for key, value in conc.items():\n",
    "        atoms_number = value * Na / masses[key]\n",
    "        atomic_numbers[key] = atoms_number\n",
    "\n",
    "    at_fractions = {}\n",
    "    for key, value in atomic_numbers.items():\n",
    "        at_frac = value / (sum(atomic_numbers.values()) + fe_atoms)\n",
    "        at_fractions[key] = at_frac\n",
    "    \n",
    "    return list(at_fractions.values())\n",
    "\n",
    "### input variables\n",
    "# Segregation energies\n",
    "df_seg = pd.read_csv('S3_1_single_site.csv', index_col=0)\n",
    "e_as = seg_energies('As', data_frame=df_seg)\n",
    "e_cr = seg_energies('Cr', data_frame=df_seg)\n",
    "e_ni = seg_energies('Ni', data_frame=df_seg)\n",
    "e_sb = seg_energies('Sb', data_frame=df_seg)\n",
    "e_sn = seg_energies('Sn', data_frame=df_seg)\n",
    "e_mo = seg_energies('Mo', data_frame=df_seg)\n",
    "mi = seg_energies('multiplicity', data_frame=df_seg)\n",
    "\n",
    "# Diffusion data\n",
    "## Diffusion coefficients, D0 (m2/s)\n",
    "as_do = 3.6e-5 # taken same as ni\n",
    "sb_do = 5e-5\n",
    "sn_do = 3.3e-5 \n",
    "ni_do = 3.6e-5\n",
    "cr_do = 7.7e-5\n",
    "mo_do = 5.9e-5\n",
    "\n",
    "## Activation energies, QA (eV)\n",
    "as_q = 2.656 # taken same as ni\n",
    "sb_q = 2.424\n",
    "sn_q = 2.355\n",
    "ni_q = 2.656 \n",
    "cr_q = 2.732\n",
    "mo_q = 2.650"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model(run_time: int, dt: float, accuracy: float, T0: float, Temb: float, R_G: float, Q_A: float, D0: float,\n",
    "                  x_bulk: float, GB_thickness: float, E: float, A: float, gb_conc: float):\n",
    "    \n",
    "    # Constants\n",
    "    R_g = (8.314 / (1.602 * 10 ** (-19))) / (6.022 * 10 ** (23))  # gas constant in eV/K --> Boltzmann constant\n",
    "\n",
    "    # Initializing empty list for saving the results\n",
    "    Ts = list()\n",
    "    gb_concs = list()\n",
    "    ife = list()\n",
    "    times = list()\n",
    "\n",
    "    # Model specific parameters\n",
    "    m = 1\n",
    "    N_tot = 1\n",
    "    f = gb_site_fraction(R_G=R_G, gb_width=GB_thickness) \n",
    "    fi = f * m/N_tot\n",
    "    fg = fi / f \n",
    "    x_hat_ki = gb_conc \n",
    "    x_global = (1 - f) * x_bulk + fi * x_hat_ki\n",
    "    x_hat_sum = fi * x_hat_ki\n",
    "    x_bulk_start = x_bulk \n",
    "\n",
    "\n",
    "    # Starting value for optimization\n",
    "    lamda = 0.001\n",
    "\n",
    "    def obj_func(lamda, Rg_T, x_hat_sum):\n",
    "        # x_hat_sum is going to be uptated\n",
    "        nom = np.exp( -(E - lamda) / Rg_T)\n",
    "        nom = np.clip(nom, a_min=None, a_max=1e300)  # Clip the exponential values\n",
    "\n",
    "        denom = 1 + np.exp( -(E - lamda) / Rg_T)\n",
    "\n",
    "        xk_i_hat_temp = nom/denom \n",
    "        xk_hat_temp = fi * xk_i_hat_temp # temporary GB content\n",
    "\n",
    "        # absolute difference between xk_hat_temp_ and xk_hat_previous\n",
    "        abs_difference = np.abs(xk_hat_temp - x_hat_sum) \n",
    "        return abs_difference\n",
    "    \n",
    "    # Set the optimization options\n",
    "    options = {'disp': False, 'xatol': accuracy}\n",
    "\n",
    "\n",
    "    t = 0\n",
    "    while t < int(run_time):\n",
    "\n",
    "        # Calculate current temperature\n",
    "        T = linear_heat_treatment(T0=T0, t_tot=run_time, Tend=Temb, t=t)\n",
    "\n",
    "        Ts.append(T)\n",
    "        Rg_T = R_g*T\n",
    "\n",
    "        # Calculate current diffusion coefficient\n",
    "        D = diff_coef(D0=D0, dQ=Q_A, T=T)\n",
    "\n",
    "        # Perform minimization\n",
    "        result_value = 1\n",
    "        rv_i = 0\n",
    "        while abs(result_value) > accuracy: \n",
    "            # Optimization using Nelder-Mead algorithm\n",
    "            result = minimize(obj_func, lamda, args=(Rg_T, x_hat_sum), method=\"Nelder-Mead\", options=options)\n",
    "            new_lamda = result.x\n",
    "            lamda = new_lamda\n",
    "            result_value = result.fun\n",
    "            rv_i += 1\n",
    "            if rv_i > 10: # for checking, 10 is guessed\n",
    "                print(result_value)\n",
    "                break\n",
    "        \n",
    "        # calculate x_hat_ki with new lamda\n",
    "        nom = np.exp( -(E - lamda) / Rg_T)\n",
    "        nom = np.clip(nom, a_min=None, a_max=1e300)  # Clip the exponential values\n",
    "\n",
    "        denom = 1 + np.exp( -(E - lamda) / Rg_T)\n",
    "\n",
    "        x_hat_ki = nom/denom\n",
    "        \n",
    "        # store results\n",
    "        gb_concs.append(x_hat_ki * fg) # questionabel if with fg or not, most likely not\n",
    "        \n",
    "        # update gb concentrations with new lamda\n",
    "\n",
    "        nom_ln = 1 - x_bulk\n",
    "        denom_ln = x_bulk\n",
    "        frac_ln = np.log(nom_ln/denom_ln)\n",
    "\n",
    "        lamda_frac = lamda/Rg_T\n",
    "\n",
    "        lhs = 15*x_bulk*D/(R_G**2)\n",
    "\n",
    "        dx_hat = (-frac_ln - lamda_frac) * lhs # dx_hat is the sum(fi * dx_hat_ki)\n",
    "\n",
    "        if np.isnan(dx_hat).any():\n",
    "                    raise ValueError(\"NaN value encountered in rhs. Stopping calculation.\")\n",
    "\n",
    "        x_hat_sum = x_hat_sum + dx_hat * dt\n",
    "    \n",
    "        # x_bulk needs to be updated as well\n",
    "        # keep in mind that x_bulk will always be almost the same as x_global\n",
    "        x_bulk = (x_global - x_hat_sum) / (1-f)\n",
    "\n",
    "\n",
    "        ife.append((x_hat_sum * fg - x_bulk_start)/A)\n",
    "\n",
    "        times.append(t)\n",
    "        t = t + dt\n",
    "\n",
    "    return gb_concs, ife, Ts, times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling \n",
    "- Using the cell magic `%%timeit` we can measure the time. Per default: the code is executed 7 times.\n",
    "- For statistics we can use any number of repititions, e.g. `%%timeit -r 3`.\n",
    "- Finally, the cell magic returns mean & std. dev per loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.6 s ± 344 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3\n",
    "# System dependent data\n",
    "A = 4.0149523035772177*6.9541013797614433/100 # in nm2\n",
    "GB_thickness = 8.4e-10 # m \n",
    "\n",
    "# initialize starting values for concentrations, take from McLean\n",
    "x_bulk = 0.0004942285667828602\n",
    "x_hat_start = 0.47854028493419043\n",
    "E = e_sn\n",
    "\n",
    " \n",
    "first_run = simple_model(run_time=3600, dt=0.1, accuracy=1e-6, T0=2000, Temb=500, R_G=100e-6, Q_A=sn_q, D0=sn_do, x_bulk=x_bulk,\n",
    "                        GB_thickness=GB_thickness, E=E, A=A, gb_conc=x_hat_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.xlabel(\"Time, $t$ ($s$)\", fontsize=12)\n",
    "plt.ylabel(\"GB occupation (-)\", fontsize=12)\n",
    "plt.plot(first_run[0], lw=2, label=\"Sn\")\n",
    "plt.legend(fontsize=12)\n",
    "plt.xticks()\n",
    "plt.grid()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we still do not know which part of the code consumes the most of the time!\n",
    "\n",
    "To investigate this further, different profiling tools can be used. Python offers buil-in methods like `cProfile` and `profile`. Both are the same and should produce the same output. The difference is, that `cProfile` is a C extension, while `profile` is pure python. Also, `profile` comes with significantly more overhead than the other.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cooling speed = 1500.0 C/h\n",
      "1.2059113883284282e-05\n",
      "x_global = 0.0005062752262108795\n",
      "         42989547 function calls in 126.118 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "    36001    0.062    0.000    0.062    0.000 3011628812.py:14(linear_heat_treatment)\n",
      "        1    0.000    0.000    0.000    0.000 3011628812.py:23(gb_site_fraction)\n",
      "    36001    0.172    0.000    0.172    0.000 3011628812.py:8(diff_coef)\n",
      "        1    3.711    3.711  126.105  126.105 525834321.py:1(simple_model)\n",
      "  1224168   34.918    0.000   45.216    0.000 525834321.py:30(obj_func)\n",
      "  1224168    0.728    0.000    1.513    0.000 <frozen abc>:117(__instancecheck__)\n",
      "        1    0.013    0.013  126.118  126.118 <string>:1(<module>)\n",
      "    36001    0.052    0.000    0.298    0.000 _methods.py:55(_any)\n",
      "  1260169    4.435    0.000    4.435    0.000 _methods.py:90(_clip)\n",
      "    36001    0.226    0.000    0.257    0.000 _minimize.py:1019(standardize_constraints)\n",
      "    36001    1.291    0.000  121.268    0.003 _minimize.py:51(minimize)\n",
      "    36001    0.016    0.000    0.016    0.000 _optimize.py:135(_wrap_callback)\n",
      "   612084    0.231    0.000    0.231    0.000 _optimize.py:156(_call_callback_maybe_halt)\n",
      "    72002    0.067    0.000    0.067    0.000 _optimize.py:221(__getattr__)\n",
      "    36001    0.027    0.000    0.027    0.000 _optimize.py:267(_check_unknown_options)\n",
      "    36001    0.055    0.000    0.055    0.000 _optimize.py:608(_wrap_scalar_function_maxfun_validation)\n",
      "  1224168    7.899    0.000   63.310    0.000 _optimize.py:615(function_wrapper)\n",
      "    36001   29.886    0.001  118.525    0.003 _optimize.py:760(_minimize_neldermead)\n",
      "   684086    0.216    0.000    0.216    0.000 fromnumeric.py:1021(_argsort_dispatcher)\n",
      "   684086    0.944    0.000    4.363    0.000 fromnumeric.py:1025(argsort)\n",
      "   612084    0.189    0.000    0.189    0.000 fromnumeric.py:1764(_ravel_dispatcher)\n",
      "   612084    1.232    0.000    2.125    0.000 fromnumeric.py:1768(ravel)\n",
      "  1260169    0.504    0.000    0.504    0.000 fromnumeric.py:2096(_clip_dispatcher)\n",
      "  1260169    2.193    0.000   10.146    0.000 fromnumeric.py:2100(clip)\n",
      "    36001    0.015    0.000    0.015    0.000 fromnumeric.py:2317(_any_dispatcher)\n",
      "    36001    0.097    0.000    0.826    0.000 fromnumeric.py:2322(any)\n",
      "   648085    0.201    0.000    0.201    0.000 fromnumeric.py:2687(_max_dispatcher)\n",
      "   648085    1.309    0.000    8.061    0.000 fromnumeric.py:2692(max)\n",
      "    36001    0.011    0.000    0.011    0.000 fromnumeric.py:2831(_min_dispatcher)\n",
      "    36001    0.065    0.000    0.349    0.000 fromnumeric.py:2836(min)\n",
      "  3312427    3.985    0.000   15.428    0.000 fromnumeric.py:53(_wrapfunc)\n",
      "   720087    2.744    0.000    7.766    0.000 fromnumeric.py:71(_wrapreduction)\n",
      "   720087    1.186    0.000    1.186    0.000 fromnumeric.py:72(<dictcomp>)\n",
      "  1368172    0.416    0.000    0.416    0.000 fromnumeric.py:91(_take_dispatcher)\n",
      "  1368172    1.671    0.000    5.727    0.000 fromnumeric.py:95(take)\n",
      "  1224168    0.364    0.000    0.364    0.000 function_base.py:869(_copy_dispatcher)\n",
      "  1224168    1.023    0.000    3.070    0.000 function_base.py:873(copy)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:127(_event_pipe)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:243(schedule)\n",
      "        6    0.000    0.000    0.000    0.000 iostream.py:505(_is_master_process)\n",
      "        6    0.000    0.000    0.000    0.000 iostream.py:532(_schedule_flush)\n",
      "        6    0.000    0.000    0.000    0.000 iostream.py:610(write)\n",
      "    36001    0.015    0.000    0.015    0.000 multiarray.py:1080(copyto)\n",
      "  1224168    2.755    0.000    5.894    0.000 numeric.py:1855(isscalar)\n",
      "    36001    0.294    0.000    0.361    0.000 numeric.py:274(full)\n",
      "    72002    0.130    0.000    0.205    0.000 numerictypes.py:283(issubclass_)\n",
      "    36001    0.176    0.000    0.389    0.000 numerictypes.py:357(issubdtype)\n",
      "    72002    0.019    0.000    0.019    0.000 shape_base.py:19(_atleast_1d_dispatcher)\n",
      "    72002    0.291    0.000    0.373    0.000 shape_base.py:23(atleast_1d)\n",
      "        1    0.000    0.000    0.000    0.000 socket.py:621(send)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1125(_wait_for_tstate_lock)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1192(is_alive)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:575(is_set)\n",
      "    36001    0.013    0.000    0.013    0.000 type_check.py:79(_asfarray_dispatcher)\n",
      "    36001    0.112    0.000    0.535    0.000 type_check.py:83(asfarray)\n",
      "  1224168    0.785    0.000    0.785    0.000 {built-in method _abc._abc_instancecheck}\n",
      "    72002    0.042    0.000    0.042    0.000 {built-in method builtins.abs}\n",
      "    72002    0.029    0.000    0.029    0.000 {built-in method builtins.callable}\n",
      "        1    0.000    0.000  126.118  126.118 {built-in method builtins.exec}\n",
      "  3384429    1.241    0.000    1.241    0.000 {built-in method builtins.getattr}\n",
      "  3132428    1.890    0.000    3.403    0.000 {built-in method builtins.isinstance}\n",
      "   108003    0.082    0.000    0.082    0.000 {built-in method builtins.issubclass}\n",
      "   108009    0.053    0.000    0.053    0.000 {built-in method builtins.len}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "  1260169    2.113    0.000    2.113    0.000 {built-in method numpy.array}\n",
      "   684086    0.228    0.000    0.228    0.000 {built-in method numpy.asanyarray}\n",
      "  1296170    0.417    0.000    0.417    0.000 {built-in method numpy.asarray}\n",
      "    72002    0.132    0.000    0.132    0.000 {built-in method numpy.empty}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        6    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "    36001    0.084    0.000    0.381    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "   216006    0.071    0.000    0.071    0.000 {method 'append' of 'list' objects}\n",
      "   684086    2.309    0.000    2.309    0.000 {method 'argsort' of 'numpy.ndarray' objects}\n",
      "  1260169    1.314    0.000    5.749    0.000 {method 'clip' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "    36001    0.114    0.000    0.114    0.000 {method 'flatten' of 'numpy.ndarray' objects}\n",
      "  1224168    0.499    0.000    0.499    0.000 {method 'item' of 'numpy.ndarray' objects}\n",
      "   720087    0.257    0.000    0.257    0.000 {method 'items' of 'dict' objects}\n",
      "    36001    0.031    0.000    0.031    0.000 {method 'lower' of 'str' objects}\n",
      "   612084    0.471    0.000    0.471    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "  1332171    5.773    0.000    5.773    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "  1368172    2.225    0.000    2.225    0.000 {method 'take' of 'numpy.ndarray' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# System dependent data\n",
    "A = 4.0149523035772177*6.9541013797614433/100 # in nm2\n",
    "GB_thickness = 8.4e-10 # m \n",
    "\n",
    "# initialize starting values for concentrations, take from McLean\n",
    "x_bulk = 0.0004942285667828602\n",
    "x_hat_start = 0.47854028493419043\n",
    "E = e_sn\n",
    "\n",
    "cProfile.run(\"simple_model(run_time=3600, dt=0.1, accuracy=1e-6, T0=2000, Temb=500, R_G=100e-6, Q_A=sn_q, D0=sn_do, x_bulk=x_bulk, GB_thickness=GB_thickness, E=E, A=A, gb_conc=x_hat_start)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column headings are:\n",
    "\n",
    "- `ncalls`: number of calls\n",
    "- `totime`: total time spent in the given function (excluding time spent in subfunctions)\n",
    "    - `percall`: `totime`/`ncalls`\n",
    "- `cumtime`: cummulative time spent in this function and all subfunctions\n",
    "    - `percall`: `cumime`/`ncalls`\n",
    "- `filename`: function identification\n",
    "\n",
    "\n",
    "Of course, `cProfile` has a magic cell command `%prun`, which we can use instead of invoking `cProfile` manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         42989488 function calls in 58.135 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "  1224168   16.330    0.000   21.068    0.000 2009487786.py:27(obj_func)\n",
      "    36001   13.744    0.000   54.788    0.002 _optimize.py:760(_minimize_neldermead)\n",
      "  1224168    3.668    0.000   29.443    0.000 _optimize.py:615(function_wrapper)\n",
      "  1332171    2.502    0.000    2.502    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "  1260169    2.006    0.000    2.006    0.000 _methods.py:90(_clip)\n",
      "  3312427    1.934    0.000    7.090    0.000 fromnumeric.py:53(_wrapfunc)\n",
      "        1    1.677    1.677   58.127   58.127 2009487786.py:1(simple_model)\n",
      "  1224168    1.271    0.000    2.732    0.000 numeric.py:1855(isscalar)\n",
      "   720087    1.206    0.000    3.402    0.000 fromnumeric.py:71(_wrapreduction)\n",
      "  1368172    1.019    0.000    1.019    0.000 {method 'take' of 'numpy.ndarray' objects}\n",
      "  1260169    1.013    0.000    4.656    0.000 fromnumeric.py:2100(clip)\n",
      "   684086    0.990    0.000    0.990    0.000 {method 'argsort' of 'numpy.ndarray' objects}\n",
      "  1260169    0.939    0.000    0.939    0.000 {built-in method numpy.array}\n",
      "  3132422    0.885    0.000    1.585    0.000 {built-in method builtins.isinstance}\n",
      "  1368172    0.824    0.000    2.752    0.000 fromnumeric.py:95(take)\n",
      "  1260169    0.615    0.000    2.621    0.000 {method 'clip' of 'numpy.ndarray' objects}\n",
      "   648085    0.596    0.000    3.558    0.000 fromnumeric.py:2692(max)\n",
      "   612084    0.584    0.000    0.999    0.000 fromnumeric.py:1768(ravel)\n",
      "  3384429    0.562    0.000    0.562    0.000 {built-in method builtins.getattr}\n",
      "    36001    0.560    0.000   55.964    0.002 _minimize.py:51(minimize)\n",
      "   720087    0.553    0.000    0.553    0.000 fromnumeric.py:72(<dictcomp>)\n",
      "  1224168    0.489    0.000    1.399    0.000 function_base.py:873(copy)\n",
      "   684086    0.475    0.000    1.994    0.000 fromnumeric.py:1025(argsort)\n",
      "  1224168    0.354    0.000    0.354    0.000 {built-in method _abc._abc_instancecheck}\n",
      "  1224168    0.346    0.000    0.701    0.000 <frozen abc>:117(__instancecheck__)\n",
      "  1260169    0.240    0.000    0.240    0.000 fromnumeric.py:2096(_clip_dispatcher)\n",
      "  1224168    0.230    0.000    0.230    0.000 {method 'item' of 'numpy.ndarray' objects}\n",
      "   612084    0.217    0.000    0.217    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "  1368172    0.203    0.000    0.203    0.000 fromnumeric.py:91(_take_dispatcher)\n",
      "  1296170    0.192    0.000    0.192    0.000 {built-in method numpy.asarray}\n",
      "  1224168    0.175    0.000    0.175    0.000 function_base.py:869(_copy_dispatcher)\n",
      "    72002    0.129    0.000    0.166    0.000 shape_base.py:23(atleast_1d)\n",
      "    36001    0.125    0.000    0.154    0.000 numeric.py:274(full)\n",
      "   720087    0.120    0.000    0.120    0.000 {method 'items' of 'dict' objects}\n",
      "   612084    0.113    0.000    0.113    0.000 _optimize.py:156(_call_callback_maybe_halt)\n",
      "   684086    0.106    0.000    0.106    0.000 {built-in method numpy.asanyarray}\n",
      "   684086    0.105    0.000    0.105    0.000 fromnumeric.py:1021(_argsort_dispatcher)\n",
      "   648085    0.098    0.000    0.098    0.000 fromnumeric.py:2687(_max_dispatcher)\n",
      "   612084    0.094    0.000    0.094    0.000 fromnumeric.py:1764(_ravel_dispatcher)\n",
      "    36001    0.089    0.000    0.103    0.000 _minimize.py:1019(standardize_constraints)\n",
      "    36001    0.075    0.000    0.164    0.000 numerictypes.py:357(issubdtype)\n",
      "    36001    0.074    0.000    0.074    0.000 3011628812.py:8(diff_coef)\n",
      "    72002    0.056    0.000    0.086    0.000 numerictypes.py:283(issubclass_)\n",
      "    72002    0.055    0.000    0.055    0.000 {built-in method numpy.empty}\n",
      "    36001    0.048    0.000    0.227    0.000 type_check.py:83(asfarray)\n",
      "    36001    0.045    0.000    0.045    0.000 {method 'flatten' of 'numpy.ndarray' objects}\n",
      "    36001    0.044    0.000    0.353    0.000 fromnumeric.py:2322(any)\n",
      "    36001    0.037    0.000    0.161    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
      "   108003    0.033    0.000    0.033    0.000 {built-in method builtins.issubclass}\n",
      "   216006    0.032    0.000    0.032    0.000 {method 'append' of 'list' objects}\n",
      "    36001    0.030    0.000    0.159    0.000 fromnumeric.py:2836(min)\n",
      "    72002    0.028    0.000    0.028    0.000 _optimize.py:221(__getattr__)\n",
      "    36001    0.027    0.000    0.027    0.000 3011628812.py:14(linear_heat_treatment)\n",
      "    36001    0.025    0.000    0.025    0.000 _optimize.py:608(_wrap_scalar_function_maxfun_validation)\n",
      "    36001    0.024    0.000    0.124    0.000 _methods.py:55(_any)\n",
      "   108003    0.023    0.000    0.023    0.000 {built-in method builtins.len}\n",
      "    72002    0.018    0.000    0.018    0.000 {built-in method builtins.abs}\n",
      "    36001    0.012    0.000    0.012    0.000 {method 'lower' of 'str' objects}\n",
      "    72002    0.012    0.000    0.012    0.000 {built-in method builtins.callable}\n",
      "    36001    0.012    0.000    0.012    0.000 _optimize.py:267(_check_unknown_options)\n",
      "    72002    0.009    0.000    0.009    0.000 shape_base.py:19(_atleast_1d_dispatcher)\n",
      "        1    0.008    0.008   58.135   58.135 <string>:1(<module>)\n",
      "    36001    0.007    0.000    0.007    0.000 fromnumeric.py:2317(_any_dispatcher)\n",
      "    36001    0.007    0.000    0.007    0.000 _optimize.py:135(_wrap_callback)\n",
      "    36001    0.007    0.000    0.007    0.000 multiarray.py:1080(copyto)\n",
      "    36001    0.006    0.000    0.006    0.000 type_check.py:79(_asfarray_dispatcher)\n",
      "    36001    0.005    0.000    0.005    0.000 fromnumeric.py:2831(_min_dispatcher)\n",
      "        1    0.000    0.000   58.135   58.135 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 3011628812.py:23(gb_site_fraction)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}"
     ]
    }
   ],
   "source": [
    "%prun simple_model(run_time=3600, dt=0.1, accuracy=1e-6, T0=2000, Temb=500, R_G=100e-6, Q_A=sn_q, D0=sn_do, x_bulk=x_bulk, GB_thickness=GB_thickness, E=E, A=A, gb_conc=x_hat_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cooling speed = 1500.0 C/h\n",
      "1.2059113883284282e-05\n",
      "x_global = 0.0005062752262108795\n",
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         42989547 function calls in 128.087 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "  1224168   35.296    0.000   45.809    0.000 525834321.py:30(obj_func)\n",
      "    36001   30.466    0.001  120.464    0.003 _optimize.py:760(_minimize_neldermead)\n",
      "  1224168    8.008    0.000   64.189    0.000 _optimize.py:615(function_wrapper)\n",
      "  1332171    5.853    0.000    5.853    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "  1260169    4.409    0.000    4.409    0.000 _methods.py:90(_clip)\n",
      "  3312427    4.155    0.000   15.742    0.000 fromnumeric.py:53(_wrapfunc)\n",
      "        1    3.753    3.753  128.074  128.074 525834321.py:1(simple_model)\n",
      "  1224168    2.768    0.000    5.972    0.000 numeric.py:1855(isscalar)\n",
      "   720087    2.675    0.000    7.790    0.000 fromnumeric.py:71(_wrapreduction)\n",
      "   684086    2.333    0.000    2.333    0.000 {method 'argsort' of 'numpy.ndarray' objects}\n",
      "  1260169    2.285    0.000   10.343    0.000 fromnumeric.py:2100(clip)\n",
      "  1368172    2.283    0.000    2.283    0.000 {method 'take' of 'numpy.ndarray' objects}\n",
      "  1260169    2.153    0.000    2.153    0.000 {built-in method numpy.array}\n",
      "  3132428    1.948    0.000    3.476    0.000 {built-in method builtins.isinstance}\n",
      "  1368172    1.762    0.000    5.966    0.000 fromnumeric.py:95(take)\n",
      "  1260169    1.382    0.000    5.790    0.000 {method 'clip' of 'numpy.ndarray' objects}\n",
      "   648085    1.295    0.000    8.074    0.000 fromnumeric.py:2692(max)\n",
      "    36001    1.288    0.000  123.196    0.003 _minimize.py:51(minimize)\n",
      "  3384429    1.261    0.000    1.261    0.000 {built-in method builtins.getattr}\n",
      "   612084    1.257    0.000    2.179    0.000 fromnumeric.py:1768(ravel)\n",
      "   720087    1.209    0.000    1.209    0.000 fromnumeric.py:72(<dictcomp>)\n",
      "  1224168    1.046    0.000    3.131    0.000 function_base.py:873(copy)\n",
      "   684086    0.992    0.000    4.471    0.000 fromnumeric.py:1025(argsort)\n",
      "  1224168    0.795    0.000    0.795    0.000 {built-in method _abc._abc_instancecheck}\n",
      "  1224168    0.733    0.000    1.528    0.000 <frozen abc>:117(__instancecheck__)\n",
      "  1260169    0.516    0.000    0.516    0.000 fromnumeric.py:2096(_clip_dispatcher)\n",
      "  1224168    0.512    0.000    0.512    0.000 {method 'item' of 'numpy.ndarray' objects}\n",
      "   612084    0.485    0.000    0.485    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "  1368172    0.425    0.000    0.425    0.000 fromnumeric.py:91(_take_dispatcher)\n",
      "  1296170    0.424    0.000    0.424    0.000 {built-in method numpy.asarray}\n",
      "  1224168    0.382    0.000    0.382    0.000 function_base.py:869(_copy_dispatcher)\n",
      "    36001    0.302    0.000    0.369    0.000 numeric.py:274(full)\n",
      "    72002    0.288    0.000    0.371    0.000 shape_base.py:23(atleast_1d)\n",
      "   720087    0.265    0.000    0.265    0.000 {method 'items' of 'dict' objects}\n",
      "   684086    0.235    0.000    0.235    0.000 {built-in method numpy.asanyarray}\n",
      "   612084    0.234    0.000    0.234    0.000 _optimize.py:156(_call_callback_maybe_halt)\n",
      "    36001    0.224    0.000    0.255    0.000 _minimize.py:1019(standardize_constraints)\n",
      "   684086    0.223    0.000    0.223    0.000 fromnumeric.py:1021(_argsort_dispatcher)\n",
      "   648085    0.205    0.000    0.205    0.000 fromnumeric.py:2687(_max_dispatcher)\n",
      "   612084    0.196    0.000    0.196    0.000 fromnumeric.py:1764(_ravel_dispatcher)\n",
      "    36001    0.177    0.000    0.396    0.000 numerictypes.py:357(issubdtype)\n",
      "    36001    0.167    0.000    0.167    0.000 3011628812.py:8(diff_coef)\n",
      "    72002    0.134    0.000    0.211    0.000 numerictypes.py:283(issubclass_)\n",
      "    72002    0.133    0.000    0.133    0.000 {built-in method numpy.empty}\n",
      "    36001    0.116    0.000    0.548    0.000 type_check.py:83(asfarray)\n",
      "    36001    0.114    0.000    0.114    0.000 {method 'flatten' of 'numpy.ndarray' objects}\n",
      "    36001    0.095    0.000    0.819    0.000 fromnumeric.py:2322(any)\n",
      "    36001    0.085    0.000    0.390    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
      "   108003    0.084    0.000    0.084    0.000 {built-in method builtins.issubclass}\n",
      "   216006    0.072    0.000    0.072    0.000 {method 'append' of 'list' objects}\n",
      "    72002    0.069    0.000    0.069    0.000 _optimize.py:221(__getattr__)\n",
      "    36001    0.063    0.000    0.349    0.000 fromnumeric.py:2836(min)\n",
      "    36001    0.062    0.000    0.062    0.000 3011628812.py:14(linear_heat_treatment)\n",
      "    36001    0.058    0.000    0.058    0.000 _optimize.py:608(_wrap_scalar_function_maxfun_validation)\n",
      "   108009    0.053    0.000    0.053    0.000 {built-in method builtins.len}\n",
      "    36001    0.052    0.000    0.305    0.000 _methods.py:55(_any)\n",
      "    72002    0.043    0.000    0.043    0.000 {built-in method builtins.abs}\n",
      "    36001    0.032    0.000    0.032    0.000 {method 'lower' of 'str' objects}\n",
      "    72002    0.028    0.000    0.028    0.000 {built-in method builtins.callable}\n",
      "    36001    0.026    0.000    0.026    0.000 _optimize.py:267(_check_unknown_options)\n",
      "    72002    0.019    0.000    0.019    0.000 shape_base.py:19(_atleast_1d_dispatcher)\n",
      "    36001    0.016    0.000    0.016    0.000 fromnumeric.py:2317(_any_dispatcher)\n",
      "    36001    0.015    0.000    0.015    0.000 _optimize.py:135(_wrap_callback)\n",
      "    36001    0.015    0.000    0.015    0.000 multiarray.py:1080(copyto)\n",
      "    36001    0.013    0.000    0.013    0.000 type_check.py:79(_asfarray_dispatcher)\n",
      "        1    0.013    0.013  128.087  128.087 <string>:1(<module>)\n",
      "    36001    0.011    0.000    0.011    0.000 fromnumeric.py:2831(_min_dispatcher)\n",
      "        1    0.000    0.000  128.087  128.087 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "        6    0.000    0.000    0.000    0.000 iostream.py:610(write)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "        1    0.000    0.000    0.000    0.000 socket.py:621(send)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:243(schedule)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1192(is_alive)\n",
      "        6    0.000    0.000    0.000    0.000 iostream.py:505(_is_master_process)\n",
      "        6    0.000    0.000    0.000    0.000 iostream.py:532(_schedule_flush)\n",
      "        1    0.000    0.000    0.000    0.000 3011628812.py:23(gb_site_fraction)\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1125(_wait_for_tstate_lock)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:127(_event_pipe)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:575(is_set)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}"
     ]
    }
   ],
   "source": [
    "# System dependent data\n",
    "A = 4.0149523035772177*6.9541013797614433/100 # in nm2\n",
    "GB_thickness = 8.4e-10 # m \n",
    "\n",
    "# initialize starting values for concentrations, take from McLean\n",
    "x_bulk = 0.0004942285667828602\n",
    "x_hat_start = 0.47854028493419043\n",
    "E = e_sn\n",
    "\n",
    "%prun simple_model(run_time=3600, dt=0.1, accuracy=1e-6, T0=2000, Temb=500, R_G=100e-6, Q_A=sn_q, D0=sn_do, x_bulk=x_bulk, GB_thickness=GB_thickness, E=E, A=A, gb_conc=x_hat_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you have a longer code and you evtl. run it on a HPC you may want to save the ouput to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 22 15:21:55 2024    profiling/stats_original_kinetic_model.stats\n",
      "\n",
      "         42989488 function calls in 57.824 seconds\n",
      "\n",
      "   Ordered by: internal time, call count\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "  1224168   16.191    0.000   20.913    0.000 2009487786.py:27(obj_func)\n",
      "    36001   13.693    0.000   54.476    0.002 _optimize.py:760(_minimize_neldermead)\n",
      "  1224168    3.645    0.000   29.219    0.000 _optimize.py:615(function_wrapper)\n",
      "  1332171    2.513    0.000    2.513    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "  1260169    1.989    0.000    1.989    0.000 _methods.py:90(_clip)\n",
      "  3312427    1.915    0.000    7.043    0.000 fromnumeric.py:53(_wrapfunc)\n",
      "        1    1.666    1.666   57.816   57.816 2009487786.py:1(simple_model)\n",
      "  1224168    1.258    0.000    2.706    0.000 numeric.py:1855(isscalar)\n",
      "   720087    1.218    0.000    3.397    0.000 fromnumeric.py:71(_wrapreduction)\n",
      "  1260169    1.024    0.000    4.647    0.000 fromnumeric.py:2100(clip)\n",
      "  1368172    1.006    0.000    1.006    0.000 {method 'take' of 'numpy.ndarray' objects}\n",
      "   684086    0.983    0.000    0.983    0.000 {method 'argsort' of 'numpy.ndarray' objects}\n",
      "  1260169    0.930    0.000    0.930    0.000 {built-in method numpy.array}\n",
      "  3132422    0.875    0.000    1.569    0.000 {built-in method builtins.isinstance}\n",
      "  1368172    0.831    0.000    2.735    0.000 fromnumeric.py:95(take)\n",
      "  1260169    0.622    0.000    2.612    0.000 {method 'clip' of 'numpy.ndarray' objects}\n",
      "   612084    0.593    0.000    1.006    0.000 fromnumeric.py:1768(ravel)\n",
      "   648085    0.588    0.000    3.542    0.000 fromnumeric.py:2692(max)\n",
      "  3384429    0.562    0.000    0.562    0.000 {built-in method builtins.getattr}\n",
      "    36001    0.560    0.000   55.657    0.002 _minimize.py:51(minimize)\n",
      "   720087    0.527    0.000    0.527    0.000 fromnumeric.py:72(<dictcomp>)\n",
      "  1224168    0.481    0.000    1.384    0.000 function_base.py:873(copy)\n",
      "   684086    0.475    0.000    1.990    0.000 fromnumeric.py:1025(argsort)\n",
      "  1224168    0.351    0.000    0.351    0.000 {built-in method _abc._abc_instancecheck}\n",
      "  1224168    0.344    0.000    0.695    0.000 <frozen abc>:117(__instancecheck__)\n",
      "  1260169    0.234    0.000    0.234    0.000 fromnumeric.py:2096(_clip_dispatcher)\n",
      "  1224168    0.225    0.000    0.225    0.000 {method 'item' of 'numpy.ndarray' objects}\n",
      "   612084    0.218    0.000    0.218    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "  1368172    0.197    0.000    0.197    0.000 fromnumeric.py:91(_take_dispatcher)\n",
      "  1296170    0.192    0.000    0.192    0.000 {built-in method numpy.asarray}\n",
      "  1224168    0.175    0.000    0.175    0.000 function_base.py:869(_copy_dispatcher)\n",
      "    72002    0.127    0.000    0.163    0.000 shape_base.py:23(atleast_1d)\n",
      "    36001    0.125    0.000    0.155    0.000 numeric.py:274(full)\n",
      "   720087    0.119    0.000    0.119    0.000 {method 'items' of 'dict' objects}\n",
      "   612084    0.112    0.000    0.112    0.000 _optimize.py:156(_call_callback_maybe_halt)\n",
      "   684086    0.104    0.000    0.104    0.000 {built-in method numpy.asanyarray}\n",
      "   684086    0.102    0.000    0.102    0.000 fromnumeric.py:1021(_argsort_dispatcher)\n",
      "   612084    0.098    0.000    0.098    0.000 fromnumeric.py:1764(_ravel_dispatcher)\n",
      "   648085    0.096    0.000    0.096    0.000 fromnumeric.py:2687(_max_dispatcher)\n",
      "    36001    0.091    0.000    0.104    0.000 _minimize.py:1019(standardize_constraints)\n",
      "    36001    0.075    0.000    0.075    0.000 3011628812.py:8(diff_coef)\n",
      "    36001    0.075    0.000    0.166    0.000 numerictypes.py:357(issubdtype)\n",
      "    72002    0.057    0.000    0.088    0.000 numerictypes.py:283(issubclass_)\n",
      "    72002    0.057    0.000    0.057    0.000 {built-in method numpy.empty}\n",
      "    36001    0.049    0.000    0.230    0.000 type_check.py:83(asfarray)\n",
      "    36001    0.046    0.000    0.046    0.000 {method 'flatten' of 'numpy.ndarray' objects}\n",
      "    36001    0.043    0.000    0.357    0.000 fromnumeric.py:2322(any)\n",
      "    36001    0.039    0.000    0.165    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
      "   108003    0.034    0.000    0.034    0.000 {built-in method builtins.issubclass}\n",
      "   216006    0.032    0.000    0.032    0.000 {method 'append' of 'list' objects}\n",
      "    36001    0.030    0.000    0.159    0.000 fromnumeric.py:2836(min)\n",
      "    72002    0.028    0.000    0.028    0.000 _optimize.py:221(__getattr__)\n",
      "    36001    0.026    0.000    0.026    0.000 3011628812.py:14(linear_heat_treatment)\n",
      "    36001    0.025    0.000    0.025    0.000 _optimize.py:608(_wrap_scalar_function_maxfun_validation)\n",
      "    36001    0.023    0.000    0.126    0.000 _methods.py:55(_any)\n",
      "   108003    0.023    0.000    0.023    0.000 {built-in method builtins.len}\n",
      "    72002    0.020    0.000    0.020    0.000 {built-in method builtins.abs}\n",
      "    36001    0.013    0.000    0.013    0.000 {method 'lower' of 'str' objects}\n",
      "    72002    0.012    0.000    0.012    0.000 {built-in method builtins.callable}\n",
      "    36001    0.011    0.000    0.011    0.000 _optimize.py:267(_check_unknown_options)\n",
      "    72002    0.009    0.000    0.009    0.000 shape_base.py:19(_atleast_1d_dispatcher)\n",
      "        1    0.008    0.008   57.824   57.824 <string>:1(<module>)\n",
      "    36001    0.007    0.000    0.007    0.000 fromnumeric.py:2317(_any_dispatcher)\n",
      "    36001    0.007    0.000    0.007    0.000 _optimize.py:135(_wrap_callback)\n",
      "    36001    0.007    0.000    0.007    0.000 multiarray.py:1080(copyto)\n",
      "    36001    0.006    0.000    0.006    0.000 type_check.py:79(_asfarray_dispatcher)\n",
      "    36001    0.005    0.000    0.005    0.000 fromnumeric.py:2831(_min_dispatcher)\n",
      "        1    0.000    0.000   57.824   57.824 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 3011628812.py:23(gb_site_fraction)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f709668a310>"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cProfile\n",
    "from pstats import Stats, SortKey\n",
    "\n",
    "filename=\"profiling/stats_original_kinetic_model.stats\"\n",
    "\n",
    "cProfile.run(\"simple_model(run_time=3600, dt=0.1, accuracy=1e-6, T0=2000, Temb=500, R_G=100e-6, Q_A=sn_q, D0=sn_do, x_bulk=x_bulk, GB_thickness=GB_thickness, E=E, A=A, gb_conc=x_hat_start)\", filename)\n",
    "\n",
    "stats = Stats(filename)\n",
    "\n",
    "# options\n",
    "stats.strip_dirs() # strips full path of functions\n",
    "stats.sort_stats(SortKey.TIME, SortKey.CALLS)\n",
    "stats.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that most of the time is spent with the minimization $\\dots$ as expected! \n",
    "\n",
    "Breakdown:\n",
    "1. obj_func:\n",
    "- The obj_func was called 1,224,168 times.\n",
    "- Total time spent in this function: 16.330 seconds.\n",
    "- Cumulative time (including calls made by this function): 21.068 seconds.\n",
    "36001 13.744 0.000 54.788 0.002 _optimize.py:760(_minimize_neldermead):\n",
    "\n",
    "2. The minimize function from scipy.optimize was called 36,001 times.\n",
    "- Total time spent in this function: 13.744 seconds.\n",
    "- Cumulative time: 54.788 seconds.\n",
    "- 1224168 3.668 0.000 29.443 0.000 _optimize.py:615(function_wrapper):\n",
    "\n",
    "3. The function wrapper was called 1,224,168 times.\n",
    "- Total time spent in this function: 3.668 seconds.\n",
    "- Cumulative time: 29.443 seconds.\n",
    "\n",
    "4. Other Lines:\n",
    "- Other lines like _methods.py:90(_clip) and fromnumeric.py:53(_wrapfunc) are internal NumPy functions used frequently during the computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the **Function Wrapper**?\n",
    "\n",
    "In the context of `scipy.optimize`, the function wrapper is an internal mechanism used to call the objective function you provided (obj_func). The wrapper takes care of various tasks such as:\n",
    "\n",
    "- Handling the input arguments.\n",
    "- Ensuring that the function is called correctly with the parameters being optimized.\n",
    "- Potentially managing additional functionality like logging, parameter transformations, or handling constraints.\n",
    "\n",
    "**Implications for Performance**\n",
    "\n",
    "The profiling output suggests that a substantial amount of time is spent in the optimization process itself, particularly in the calls to the objective function and the optimization routine (minimize). The function_wrapper is part of this process, contributing to the overall computational overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we get more information?\n",
    "\n",
    "So far, we saw which functions took how long. But there is also a way to look deeper into the functions and investigate each line of a certain function. For that we use a thirdparty `line_profiler`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "%%bash\n",
    "pip install line_profiler\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension doesn't define how to unload it.\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Execute a statement under the line-by-line profiler from the\n",
      "line_profiler module.\n",
      "\n",
      "Usage:\n",
      "\n",
      "    %lprun -f func1 -f func2 <statement>\n",
      "\n",
      "The given statement (which doesn't require quote marks) is run via the\n",
      "LineProfiler. Profiling is enabled for the functions specified by the -f\n",
      "options. The statistics will be shown side-by-side with the code through the\n",
      "pager once the statement has completed.\n",
      "\n",
      "Options:\n",
      "\n",
      "-f <function>: LineProfiler only profiles functions and methods it is told\n",
      "to profile.  This option tells the profiler about these functions. Multiple\n",
      "-f options may be used. The argument may be any expression that gives\n",
      "a Python function or method object. However, one must be careful to avoid\n",
      "spaces that may confuse the option parser.\n",
      "\n",
      "-m <module>: Get all the functions/methods in a module\n",
      "\n",
      "One or more -f or -m options are required to get any useful results.\n",
      "\n",
      "-D <filename>: dump the raw statistics out to a pickle file on disk. The\n",
      "usual extension for this is \".lprof\". These statistics may be viewed later\n",
      "by running line_profiler.py as a script.\n",
      "\n",
      "-T <filename>: dump the text-formatted statistics with the code side-by-side\n",
      "out to a text file.\n",
      "\n",
      "-r: return the LineProfiler object after it has completed profiling.\n",
      "\n",
      "-s: strip out all entries from the print-out that have zeros.\n",
      "\n",
      "-u: specify time unit for the print-out in seconds.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/pycalphad/lib/python3.11/site-packages/line_profiler/ipython_extension.py"
     ]
    }
   ],
   "source": [
    "%lprun?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s"
     ]
    }
   ],
   "source": [
    "%lprun simple_model(run_time=3600, dt=0.1, accuracy=1e-6, T0=2000, Temb=500, R_G=100e-6, Q_A=sn_q, D0=sn_do, x_bulk=x_bulk, GB_thickness=GB_thickness, E=E, A=A, gb_conc=x_hat_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization of python code\n",
    "\n",
    "- Where can we speed up the code:\n",
    "    - As shown above, most of the time is spent with the minimization, scipy wrapper, and obj_function!\n",
    "- But, lets try first to all of the np.append functions:\n",
    "\n",
    "**Making numpy arrays in a loop**\n",
    "1. Using np.append(not recommended ...):\n",
    "\n",
    "    - This function does not append to a given array. Instead it creates a new array with the results appended each time. This is both **memory** and **computationally inefficient**. Especially, if we know the resulting array size appriori.\n",
    "\n",
    "2. Using pre-allocation:\n",
    "\n",
    "    - This is the most computationally efficient way, but it only works if we know in advance how big the finall array will be.\n",
    "\n",
    "3. Using a list then convert to numpy array: \n",
    "\n",
    "    - If we dont know the final size, it is more efficient if we append to a list and then convert the final result to a numpy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def simple_model(run_time: int, dt: float, accuracy: float, T0: float, Temb: float, R_G: float, Q_A: float, D0: float,\n",
    "                  x_bulk: float, GB_thickness: float, E: float, A: float, gb_conc: float):\n",
    "    \n",
    "    \n",
    "    R_g = (8.314 / (1.602 * 10 ** (-19))) / (6.022 * 10 ** (23))  # gas constant in eV/K --> Boltzmann constant\n",
    "\n",
    "    # Initializing empty list for saving the results -> We know the final size of these variable: run_time/dt\n",
    "    Ts = list()\n",
    "    gb_concs = list()\n",
    "    ife = list()\n",
    "    times = list()\n",
    "\n",
    "    # Model specific parameters\n",
    "    m = 1\n",
    "    N_tot = 1\n",
    "    f = gb_site_fraction(R_G=R_G, gb_width=GB_thickness) \n",
    "    fi = f * m/N_tot\n",
    "    fg = fi / f \n",
    "    x_hat_ki = gb_conc \n",
    "    x_global = (1 - f) * x_bulk + fi * x_hat_ki\n",
    "    x_hat_sum = fi * x_hat_ki\n",
    "    x_bulk_start = x_bulk \n",
    "\n",
    "\n",
    "    # Starting value for optimization\n",
    "    lamda = 0.001\n",
    "\n",
    "    def obj_func(lamda, Rg_T, x_hat_sum):\n",
    "        \n",
    "        nom = np.exp( -(E - lamda) / Rg_T)\n",
    "        nom = np.clip(nom, a_min=None, a_max=1e300)  \n",
    "\n",
    "        denom = 1 + np.exp( -(E - lamda) / Rg_T)\n",
    "\n",
    "        xk_i_hat_temp = nom/denom \n",
    "        xk_hat_temp = fi * xk_i_hat_temp \n",
    "\n",
    "        \n",
    "        abs_difference = np.abs(xk_hat_temp - x_hat_sum) \n",
    "        return abs_difference\n",
    "    \n",
    "    \n",
    "    options = {'disp': False, 'xatol': accuracy}\n",
    "\n",
    "\n",
    "    t = 0\n",
    "    while t < int(run_time):\n",
    "\n",
    "        # Calculate current temperature -> we can calculate the temperatures even before the main loop\n",
    "        T = linear_heat_treatment(T0=T0, t_tot=run_time, Tend=Temb, t=t)\n",
    "\n",
    "        Ts.append(T)\n",
    "        Rg_T = R_g*T\n",
    "\n",
    "        # Calculate current diffusion coefficient -> we can calculate the diffusion coefficients even before the main loop\n",
    "        D = diff_coef(D0=D0, dQ=Q_A, T=T)\n",
    "\n",
    "        # Perform minimization\n",
    "        result_value = 1\n",
    "        rv_i = 0\n",
    "        while abs(result_value) > accuracy: \n",
    "            # Optimization using Nelder-Mead algorithm\n",
    "            result = minimize(obj_func, lamda, args=(Rg_T, x_hat_sum), method=\"Nelder-Mead\", options=options)\n",
    "            new_lamda = result.x\n",
    "            lamda = new_lamda\n",
    "            result_value = result.fun\n",
    "            rv_i += 1\n",
    "            if rv_i > 10: # for checking, 10 is guessed\n",
    "                print(result_value)\n",
    "                break\n",
    "        \n",
    "        \n",
    "        nom = np.exp( -(E - lamda) / Rg_T)\n",
    "        nom = np.clip(nom, a_min=None, a_max=1e300)  \n",
    "\n",
    "        denom = 1 + np.exp( -(E - lamda) / Rg_T)\n",
    "\n",
    "        x_hat_ki = nom/denom\n",
    "        \n",
    "        #### lets try to remove all append statements as well and just write the results to the initialized np.arrays\n",
    "        gb_concs.append(x_hat_ki * fg) # questionabel if with fg or not, most likely not\n",
    "        \n",
    "        \n",
    "\n",
    "        nom_ln = 1 - x_bulk\n",
    "        denom_ln = x_bulk\n",
    "        frac_ln = np.log(nom_ln/denom_ln)\n",
    "\n",
    "        lamda_frac = lamda/Rg_T\n",
    "\n",
    "        lhs = 15*x_bulk*D/(R_G**2)\n",
    "\n",
    "        dx_hat = (-frac_ln - lamda_frac) * lhs \n",
    "\n",
    "        if np.isnan(dx_hat).any():\n",
    "                    raise ValueError(\"NaN value encountered in rhs. Stopping calculation.\")\n",
    "\n",
    "        x_hat_sum = x_hat_sum + dx_hat * dt\n",
    "    \n",
    "        \n",
    "        x_bulk = (x_global - x_hat_sum) / (1-f)\n",
    "\n",
    "        ######### here as well\n",
    "        ife.append((x_hat_sum * fg - x_bulk_start)/A)\n",
    "\n",
    "        ######## here as well\n",
    "        times.append(t)\n",
    "        t = t + dt\n",
    "\n",
    "    return gb_concs, ife, Ts, times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature and diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isothermal(Tstart: float, t_tot: int, dt: float) -> np.ndarray:\n",
    "    t_steps = np.arange(0, t_tot + dt, dt)\n",
    "    return np.full_like(t_steps, Tstart, dtype=np.float32)\n",
    "    \n",
    "def linear_heat_treatment(Tstart: float, Tend: float, t_tot: int, dt: float) -> np.ndarray:\n",
    "    t_steps = np.arange(0, t_tot + dt, dt)\n",
    "    k = (Tend - Tstart) / t_tot\n",
    "    temperatures = k * t_steps + Tstart\n",
    "    return temperatures\n",
    "\n",
    "def newton_cooling(Tstart: float, Tend: float, t_tot: int, dt: float, r: float) -> np.ndarray:\n",
    "    t_steps = np.arange(0, t_tot + dt, dt)\n",
    "    temperatures = Tend + (Tstart - Tend) * np.exp(-r * t_steps**0.5)\n",
    "    return temperatures\n",
    "\n",
    "def diff_coef(D0: float, dQ: float, T: np.ndarray, kB: float = (8.314 / (1.602 * 10**(-19))) / (6.022 * 10**(23))) -> np.ndarray:\n",
    "    diffusion_coefficients = D0 * np.exp(-dQ / (kB * T))\n",
    "    return diffusion_coefficients\n",
    "\n",
    "#######################################################################\n",
    "def get_T_and_D(t_tot: int, Tstart: float, D0: float, dQ: float, Tend: float = None, heat_treatment_type: str = \"iso\", dt: float = None, r: float = None) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    if heat_treatment_type == \"iso\":\n",
    "        temperatures = isothermal(Tstart=Tstart, t_tot=t_tot, dt=dt)\n",
    "    elif heat_treatment_type == \"linear\":\n",
    "        temperatures = linear_heat_treatment(Tstart=Tstart, Tend=Tend, t_tot=t_tot, dt=dt)\n",
    "    elif heat_treatment_type == \"newton_cooling\":\n",
    "        temperatures = newton_cooling(Tstart=Tstart, Tend=Tend, t_tot=t_tot, dt=dt, r=r)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid heat_treatment_type. Must be 'iso', 'linear', or 'newton_cooling'.\")\n",
    "\n",
    "    diffusion_coefficients = diff_coef(D0=D0, dQ=dQ, T=temperatures)\n",
    "    return temperatures, diffusion_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_model_py(t_tot: int, dt: float, accuracy: float, Tstart: float, R_G: float, D0: float, dQ: float,\n",
    "                  x_bulk: float, GB_thickness: float, E: float, A: float, gb_conc: float, Tend=None, r=None, heat_treatment_type=\"iso\"):\n",
    "    \n",
    "    \n",
    "    R_g = (8.314 / (1.602 * 10 ** (-19))) / (6.022 * 10 ** (23))  # gas constant in eV/K --> Boltzmann constant\n",
    "\n",
    "    temperatures, diffusion_coefficients = get_T_and_D(t_tot=t_tot, Tstart=Tstart, D0=D0, dQ=dQ, Tend=Tend, \n",
    "                                                        heat_treatment_type = heat_treatment_type, dt=dt, r=None)\n",
    "    Rg_Ts = temperatures * R_g\n",
    "\n",
    "    \n",
    "    # Initializing empty np.arrays for the results ->\n",
    "    # However, this time we are not appending the results but replacing the values inside\n",
    "    # an np.array with predefined size \n",
    "    gb_concs = np.empty(shape=(len(temperatures), 1), dtype=np.float32)\n",
    "    ife = np.empty(shape=(len(temperatures), 1), dtype=np.float32)\n",
    "    \n",
    "    # Model specific parameters\n",
    "    m = 1\n",
    "    N_tot = 1\n",
    "    f = gb_site_fraction(R_G=R_G, gb_width=GB_thickness) \n",
    "    fi = f * m/N_tot\n",
    "    fg = fi / f \n",
    "    x_hat_ki = gb_conc \n",
    "    x_global = (1 - f) * x_bulk + fi * x_hat_ki\n",
    "    x_hat_sum = fi * x_hat_ki\n",
    "    x_bulk_start = x_bulk \n",
    "\n",
    "\n",
    "    # Starting value for optimization\n",
    "    lamda = 0.001\n",
    "\n",
    "    def obj_func(lamda, Rg_T, x_hat_sum):\n",
    "        \n",
    "        nom = np.exp( -(E - lamda) / Rg_T)\n",
    "        nom = np.clip(nom, a_min=None, a_max=1e300)  \n",
    "\n",
    "        denom = 1 + np.exp( -(E - lamda) / Rg_T)\n",
    "\n",
    "        xk_i_hat_temp = nom/denom \n",
    "        xk_hat_temp = fi * xk_i_hat_temp \n",
    "\n",
    "        \n",
    "        abs_difference = np.abs(xk_hat_temp - x_hat_sum) \n",
    "        return abs_difference\n",
    "    \n",
    "    \n",
    "    options = {'disp': False, 'xatol': accuracy}\n",
    "\n",
    "\n",
    "    for indx in range(len(temperatures)):\n",
    "\n",
    "        # Calculate current temperature -> we can calculate the temperatures even before the main loop\n",
    "        #T = linear_heat_treatment(T0=T0, t_tot=run_time, Tend=Temb, t=t)\n",
    "        \n",
    "        #Ts.append(T) # now we can remove it\n",
    "        #Rg_T = R_g*T # we can remove this as well\n",
    "        Rg_T = Rg_Ts[indx]\n",
    "        \n",
    "        # Calculate current diffusion coefficient -> we can calculate the diffusion coefficients even before the main loop\n",
    "        #D = diff_coef(D0=D0, dQ=Q_A, T=T)\n",
    "        D = diffusion_coefficients[indx]\n",
    "        \n",
    "        # Perform minimization\n",
    "        result_value = 1\n",
    "        rv_i = 0\n",
    "        while abs(result_value) > accuracy: \n",
    "            # Optimization using Nelder-Mead algorithm\n",
    "            result = minimize(obj_func, lamda, args=(Rg_T, x_hat_sum), method=\"Nelder-Mead\", options=options)\n",
    "            new_lamda = result.x\n",
    "            lamda = new_lamda\n",
    "            result_value = result.fun\n",
    "            rv_i += 1\n",
    "            if rv_i > 10: # for checking, 10 is guessed\n",
    "                print(result_value)\n",
    "                break\n",
    "        \n",
    "        \n",
    "        nom = np.exp( -(E - lamda) / Rg_T)\n",
    "        nom = np.clip(nom, a_min=None, a_max=1e300)  \n",
    "\n",
    "        denom = 1 + np.exp( -(E - lamda) / Rg_T)\n",
    "\n",
    "        x_hat_ki = nom/denom\n",
    "        \n",
    "        #### lets try to remove all append statements as well and just write the results to the initialized np.arrays\n",
    "        #gb_concs.append(x_hat_ki * fg) # questionabel if with fg or not, most likely not\n",
    "        # we can now change the value of the array at the indx\n",
    "        gb_concs[indx] = x_hat_ki * fg\n",
    "        \n",
    "\n",
    "        nom_ln = 1 - x_bulk\n",
    "        denom_ln = x_bulk\n",
    "        frac_ln = np.log(nom_ln/denom_ln)\n",
    "\n",
    "        lamda_frac = lamda/Rg_T\n",
    "\n",
    "        lhs = 15*x_bulk*D/(R_G**2)\n",
    "\n",
    "        dx_hat = (-frac_ln - lamda_frac) * lhs \n",
    "\n",
    "        if np.isnan(dx_hat).any():\n",
    "                    raise ValueError(\"NaN value encountered in rhs. Stopping calculation.\")\n",
    "\n",
    "        x_hat_sum = x_hat_sum + dx_hat * dt\n",
    "    \n",
    "        \n",
    "        x_bulk = (x_global - x_hat_sum) / (1-f)\n",
    "\n",
    "        ######### we can now simply change the values in the predefined arrays\n",
    "        #ife.append((x_hat_sum * fg - x_bulk_start)/A)\n",
    "        ife[indx] = (x_hat_sum * fg - x_bulk_start)/A\n",
    "        \n",
    "        ######## We dont need to update the times any more\n",
    "        #times.append(t)\n",
    "        #t = t + dt\n",
    "    return gb_concs, ife"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 11s ± 6.76 s per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3\n",
    "# System dependent data\n",
    "A = 4.0149523035772177*6.9541013797614433/100 # in nm2\n",
    "GB_thickness = 8.4e-10 # m \n",
    "\n",
    "# initialize starting values for concentrations, take from McLean\n",
    "x_bulk = 0.0004942285667828602\n",
    "x_hat_start = 0.47854028493419043\n",
    "E = e_sn\n",
    "\n",
    " \n",
    "results_modified_model_py = modified_model_py(t_tot=3600, dt=0.1, accuracy=1e-6, Tstart=2000, R_G=100e-6, dQ=sn_q, D0=sn_do, x_bulk=x_bulk,\n",
    "                        GB_thickness=GB_thickness, E=E, A=A, gb_conc=x_hat_start, Tend=500, heat_treatment_type=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now that we used pre-allocation instead of append functions, we made it at least more memory efficient. In this example we do not really observe time savings, since the minimize function takes the most time. However, thinking of heavier problems with more solutes and sites and longer simulation times (hence more appends) this code corrections might also pay of with respect to computational time (and especially with repect to memory!) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f709436cd90>]"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results_modified_model_py[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cython\n",
    "\n",
    "Python is a very flexible and easy to lear programming language. It also has a lot of modules and functions which can be easily integrated. However, it is a dynamically typed language. This means that each time we run a code, the code is checked and exectuted simultaneously. This makes the code slower. In contrast, languages like C are statically typed languages and hence, the code needs to be pre-compiled. This makes the actual execution much faster. However, the language is much harder than python. Cython is a package which translates python code into C code, and in some situations can provide significant boost ups. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create Cython source file\n",
    "\n",
    "Save the source file with the magic command `%%writefile`. Cython source files need the .pyx extension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pure python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./examples/cython/heat_treatment.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./examples/cython/heat_treatment.py\n",
    "from typing import List, Tuple, Dict\n",
    "import numpy as np\n",
    "\n",
    "def isothermal(Tstart: float, t_tot: int, dt: float) -> np.ndarray:\n",
    "    t_steps = np.arange(0, t_tot + dt, dt)\n",
    "    return np.full_like(t_steps, Tstart, dtype=np.float32)\n",
    "    \n",
    "def linear_heat_treatment(Tstart: float, Tend: float, t_tot: int, dt: float) -> np.ndarray:\n",
    "    t_steps = np.arange(0, t_tot + dt, dt)\n",
    "    k = (Tend - Tstart) / t_tot\n",
    "    temperatures = k * t_steps + Tstart\n",
    "    return temperatures\n",
    "\n",
    "def newton_cooling(Tstart: float, Tend: float, t_tot: int, dt: float, r: float) -> np.ndarray:\n",
    "    t_steps = np.arange(0, t_tot + dt, dt)\n",
    "    temperatures = Tend + (Tstart - Tend) * np.exp(-r * t_steps**0.5)\n",
    "    return temperatures\n",
    "\n",
    "def diff_coef(D0: float, dQ: float, T: np.ndarray, kB: float = (8.314 / (1.602 * 10**(-19))) / (6.022 * 10**(23))) -> np.ndarray:\n",
    "    diffusion_coefficients = D0 * np.exp(-dQ / (kB * T))\n",
    "    return diffusion_coefficients\n",
    "\n",
    "#######################################################################\n",
    "def get_T_and_D(t_tot: int, Tstart: float, D0: float, dQ: float, Tend: float = None, heat_treatment_type: str = \"iso\", dt: float = None, r: float = None) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    if heat_treatment_type == \"iso\":\n",
    "        temperatures = isothermal(Tstart=Tstart, t_tot=t_tot, dt=dt)\n",
    "    elif heat_treatment_type == \"linear\":\n",
    "        temperatures = linear_heat_treatment(Tstart=Tstart, Tend=Tend, t_tot=t_tot, dt=dt)\n",
    "    elif heat_treatment_type == \"newton_cooling\":\n",
    "        temperatures = newton_cooling(Tstart=Tstart, Tend=Tend, t_tot=t_tot, dt=dt, r=r)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid heat_treatment_type. Must be 'iso', 'linear', or 'newton_cooling'.\")\n",
    "\n",
    "    diffusion_coefficients = diff_coef(D0=D0, dQ=dQ, T=temperatures)\n",
    "    return temperatures, diffusion_coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Annotated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without changing anything in the code, we can \"cythonize\" the given function. In order to do so we need to create a file with .pyx extension. We need to compile this function later with the help of a setup file and import back into python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./examples/cython/heat_treatment_annotated.pyx\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./examples/cython/heat_treatment_annotated.pyx\n",
    "import numpy as np\n",
    "\n",
    "def isothermal(Tstart: float, t_tot: int, dt: float) -> np.ndarray:\n",
    "    t_steps = np.arange(0, t_tot + dt, dt)\n",
    "    return np.full_like(t_steps, Tstart, dtype=np.float32)\n",
    "    \n",
    "def linear_heat_treatment(Tstart: float, Tend: float, t_tot: int, dt: float) -> np.ndarray:\n",
    "    t_steps = np.arange(0, t_tot + dt, dt)\n",
    "    k = (Tend - Tstart) / t_tot\n",
    "    temperatures = k * t_steps + Tstart\n",
    "    return temperatures\n",
    "\n",
    "def newton_cooling(Tstart: float, Tend: float, t_tot: int, dt: float, r: float) -> np.ndarray:\n",
    "    t_steps = np.arange(0, t_tot + dt, dt)\n",
    "    temperatures = Tend + (Tstart - Tend) * np.exp(-r * t_steps**0.5)\n",
    "    return temperatures\n",
    "\n",
    "def diff_coef(D0: float, dQ: float, T: np.ndarray, kB: float = (8.314 / (1.602 * 10**(-19))) / (6.022 * 10**(23))) -> np.ndarray:\n",
    "    diffusion_coefficients = D0 * np.exp(-dQ / (kB * T))\n",
    "    return diffusion_coefficients\n",
    "\n",
    "#######################################################################\n",
    "def get_T_and_D(t_tot: int, Tstart: float, D0: float, dQ: float, Tend: float = None, heat_treatment_type: str = \"iso\", dt: float = None, r: float = None) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    if heat_treatment_type == \"iso\":\n",
    "        temperatures = isothermal(Tstart=Tstart, t_tot=t_tot, dt=dt)\n",
    "    elif heat_treatment_type == \"linear\":\n",
    "        temperatures = linear_heat_treatment(Tstart=Tstart, Tend=Tend, t_tot=t_tot, dt=dt)\n",
    "    elif heat_treatment_type == \"newton_cooling\":\n",
    "        temperatures = newton_cooling(Tstart=Tstart, Tend=Tend, t_tot=t_tot, dt=dt, r=r)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid heat_treatment_type. Must be 'iso', 'linear', or 'newton_cooling'.\")\n",
    "\n",
    "    diffusion_coefficients = diff_coef(D0=D0, dQ=dQ, T=temperatures)\n",
    "    return temperatures, diffusion_coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is the option to have a look at how much cython needs to interact with the Python virtual machine. Wieth the command line code below, we create an annotated file in HTML, which can be opened and analyzed in the browser tab. The more yellow a line is, the more Python interaction there is. Our goal is to reduce Python interactions as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/amin/anaconda3/envs/pycalphad/lib/python3.11/site-packages/Cython/Compiler/Main.py:381: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: /home/amin/projects/gb_thermodynamics/mclean/examples/cython/heat_treatment_annotated.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n"
     ]
    }
   ],
   "source": [
    "!cython -a ./examples/cython/heat_treatment_annotated.pyx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cythonized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./examples/cython/heat_treatment_cythonized.pyx\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./examples/cython/heat_treatment_cythonized.pyx\n",
    "import numpy as np\n",
    "cimport numpy as np  # Cython-specific import for type declarations\n",
    "from libc.math cimport exp, sqrt\n",
    "\n",
    "# Function declarations\n",
    "cdef float[:] isothermal(float Tstart, int t_tot, float dt):\n",
    "    cdef int n = int(t_tot / dt) + 1\n",
    "    cdef float[:] t_steps = np.zeros(n, dtype=np.float32)\n",
    "    cdef float[:] temperatures = np.zeros(n, dtype=np.float32)\n",
    "    cdef int i\n",
    "    for i in range(n):\n",
    "        t_steps[i] = i * dt\n",
    "        temperatures[i] = Tstart\n",
    "    return temperatures\n",
    "\n",
    "cdef float[:] linear_heat_treatment(float Tstart, float Tend, int t_tot, float dt):\n",
    "    cdef int n = int(t_tot / dt) + 1\n",
    "    cdef float[:] t_steps = np.zeros(n, dtype=np.float32)\n",
    "    cdef float[:] temperatures = np.zeros(n, dtype=np.float32)\n",
    "    cdef float k = (Tend - Tstart) / t_tot\n",
    "    cdef int i\n",
    "    for i in range(n):\n",
    "        t_steps[i] = i * dt\n",
    "        temperatures[i] = k * t_steps[i] + Tstart\n",
    "    return temperatures\n",
    "\n",
    "cdef float[:] newton_cooling(float Tstart, float Tend, int t_tot, float dt, float r):\n",
    "    cdef int n = int(t_tot / dt) + 1\n",
    "    cdef float[:] t_steps = np.zeros(n, dtype=np.float32)\n",
    "    cdef float[:] temperatures = np.zeros(n, dtype=np.float32)\n",
    "    cdef int i\n",
    "    for i in range(n):\n",
    "        t_steps[i] = i * dt\n",
    "        temperatures[i] = Tend + (Tstart - Tend) * exp(-r * sqrt(t_steps[i]))\n",
    "    return temperatures\n",
    "\n",
    "cdef float[:] diff_coef(float D0, float dQ, float[:] T, float kB):\n",
    "    cdef int n = T.shape[0]\n",
    "    cdef float[:] diffusion_coefficients = np.zeros(n, dtype=np.float32)\n",
    "    cdef int i\n",
    "    for i in range(n):\n",
    "        diffusion_coefficients[i] = D0 * exp(-dQ / (kB * T[i]))\n",
    "    return diffusion_coefficients\n",
    "\n",
    "# Main function\n",
    "cpdef tuple get_T_and_D(int t_tot, float Tstart, float D0, float dQ, float dt, float Tend=-1, str heat_treatment_type=\"iso\", float r=-1):\n",
    "    cdef float[:] temperatures\n",
    "    cdef float[:] diffusion_coefficients\n",
    "    if heat_treatment_type == \"iso\":\n",
    "        temperatures = isothermal(Tstart=Tstart, t_tot=t_tot, dt=dt)\n",
    "    elif heat_treatment_type == \"linear\":\n",
    "        if Tend == -1:\n",
    "            raise ValueError(\"Tend must be provided for linear heat treatment.\")\n",
    "        temperatures = linear_heat_treatment(Tstart=Tstart, Tend=Tend, t_tot=t_tot, dt=dt)\n",
    "    elif heat_treatment_type == \"newton_cooling\":\n",
    "        if Tend == -1 or r == -1:\n",
    "            raise ValueError(\"Tend and r must be provided for Newton cooling heat treatment.\")\n",
    "        temperatures = newton_cooling(Tstart=Tstart, Tend=Tend, t_tot=t_tot, dt=dt, r=r)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid heat_treatment_type. Must be 'iso', 'linear', or 'newton_cooling'.\")\n",
    "\n",
    "    diffusion_coefficients = diff_coef(D0=D0, dQ=dQ, T=temperatures, kB=(8.314 / (1.602 * 10**(-19))) / (6.022 * 10**(23)))\n",
    "    return temperatures, diffusion_coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/amin/anaconda3/envs/pycalphad/lib/python3.11/site-packages/Cython/Compiler/Main.py:381: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: /home/amin/projects/gb_thermodynamics/mclean/examples/cython/heat_treatment_cythonized.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n"
     ]
    }
   ],
   "source": [
    "!cython -a ./examples/cython/heat_treatment_cythonized.pyx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create a setup file\n",
    "\n",
    "Create a setup.py file for buildung the Cython extension module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./examples/cython/setup_heat_treatment.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./examples/cython/setup_heat_treatment.py\n",
    "from Cython.Build import cythonize\n",
    "from setuptools import setup, Extension\n",
    "import numpy as np\n",
    "\n",
    "extensions = [\n",
    "    Extension(\n",
    "        \"heat_treatment_annotated\",\n",
    "        [\"./examples/cython/heat_treatment_annotated.pyx\"],\n",
    "        include_dirs=[np.get_include()],  # Include the NumPy headers\n",
    "    ),\n",
    "    Extension(\n",
    "        \"heat_treatment_cythonized\",\n",
    "        [\"./examples/cython/heat_treatment_cythonized.pyx\"],\n",
    "        include_dirs=[np.get_include()],  # Include the NumPy headers\n",
    "    )\n",
    "]\n",
    "\n",
    "setup(\n",
    "    ext_modules=cythonize(\n",
    "        extensions,\n",
    "        compiler_directives={'language_level': \"3\"}  # Ensure Cython uses Python 3 syntax\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Compile the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running build_ext\n",
      "building 'heat_treatment_annotated' extension\n",
      "gcc -pthread -B /home/amin/anaconda3/envs/pycalphad/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/amin/anaconda3/envs/pycalphad/include -fPIC -O2 -isystem /home/amin/anaconda3/envs/pycalphad/include -fPIC -I/home/amin/anaconda3/envs/pycalphad/lib/python3.11/site-packages/numpy/core/include -I/home/amin/anaconda3/envs/pycalphad/include/python3.11 -c ./examples/cython/heat_treatment_annotated.c -o build/temp.linux-x86_64-cpython-311/./examples/cython/heat_treatment_annotated.o\n",
      "gcc -pthread -B /home/amin/anaconda3/envs/pycalphad/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/home/amin/anaconda3/envs/pycalphad/lib -Wl,-rpath-link,/home/amin/anaconda3/envs/pycalphad/lib -L/home/amin/anaconda3/envs/pycalphad/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/home/amin/anaconda3/envs/pycalphad/lib -Wl,-rpath-link,/home/amin/anaconda3/envs/pycalphad/lib -L/home/amin/anaconda3/envs/pycalphad/lib build/temp.linux-x86_64-cpython-311/./examples/cython/heat_treatment_annotated.o -o ./examples/cython/heat_treatment_annotated.cpython-311-x86_64-linux-gnu.so\n"
     ]
    }
   ],
   "source": [
    "!python3 ./examples/cython/setup_heat_treatment.py build_ext -b ./examples/cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./examples/cython/execute_heat_treatments.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./examples/cython/execute_heat_treatments.py\n",
    "from timeit import timeit\n",
    "\n",
    "# Benchmark the get_T_and_D function\n",
    "t1 = timeit(\"get_T_and_D(t_tot=1000, Tstart=1000, D0=0.5, dQ=1.9e-9, Tend=100, dt=0.1, heat_treatment_type='linear', r=-1)\",\n",
    "            setup=\"from heat_treatment import get_T_and_D\",\n",
    "            number=10000)\n",
    "\n",
    "# Benchmark the get_T_and_D function\n",
    "t2 = timeit(\"get_T_and_D(t_tot=1000, Tstart=1000, D0=0.5, dQ=1.9e-9, Tend=100.0, dt=0.1, heat_treatment_type='linear', r=-1.0)\",\n",
    "            setup=\"from heat_treatment_annotated import get_T_and_D\",\n",
    "            number=10000)\n",
    "\n",
    "t3 = timeit(\"get_T_and_D(1000, 1000.0, 0.5, 1e-9, 1.0, 100.0, 'linear', -1.0)\",\n",
    "            setup=\"from heat_treatment_cythonized import get_T_and_D\",\n",
    "            number=10000)\n",
    "\n",
    "print(f\"Python: Time for get_T_and_D: {t1} seconds for 10k runs\")\n",
    "print(f\"Annotated: Time for get_T_and_D is {t1/t2} times faster than python for 10k runs\")\n",
    "print(f\"Cythonized: Time for get_T_and_D is {t1/t3} times faster than python for 10k runs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: Time for get_T_and_D: 0.3917671650015109 seconds for 10k runs\n",
      "Annotated: Time for get_T_and_D is 1.1146550308678274 times faster than python for 10k runs\n",
      "Cythonized: Time for get_T_and_D is 3.154767327863118 times faster than python for 10k runs\n"
     ]
    }
   ],
   "source": [
    "!python3 ./examples/cython/execute_heat_treatments.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, we see that for this example, the time we gained is marginally and basically we can leave our pure python code as it is. Reason is, that the pure python code uses anyway only numpy which is written in C. However, we still could make the code faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how much improvement can we get if we cythonize the kinetic model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization of kinetic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pure python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./examples/cython/kinetics_python.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./examples/cython/kinetics_python.py \n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from heat_treatment import get_T_and_D\n",
    "\n",
    "# Calculate fraction of GB sites compared to all sites in the system\n",
    "def gb_site_fraction(R_G=100e-6, gb_width=8.4e-10):\n",
    "    V_G = R_G**3\n",
    "    V_GB = V_G - (R_G - gb_width)**3\n",
    "    return V_GB/V_G\n",
    "\n",
    "def kinetics_python(t_tot: int, dt: float, accuracy: float, Tstart: float, R_G: float, D0: float, dQ: float,\n",
    "                  x_bulk: float, GB_thickness: float, E: float, A: float, gb_conc: float, Tend=None, r=None, heat_treatment_type=\"linear\"):\n",
    "    \n",
    "    \n",
    "    R_g = (8.314 / (1.602 * 10 ** (-19))) / (6.022 * 10 ** (23))  # gas constant in eV/K --> Boltzmann constant\n",
    "\n",
    "    temperatures, diffusion_coefficients = get_T_and_D(t_tot=t_tot, Tstart=Tstart, D0=D0, dQ=dQ, dt=dt, Tend=Tend, heat_treatment_type=heat_treatment_type, r=r)\n",
    "    Rg_Ts = temperatures * R_g\n",
    "\n",
    "    gb_concs = np.empty(shape=(len(temperatures), 1), dtype=np.float32)\n",
    "    ife = np.empty(shape=(len(temperatures), 1), dtype=np.float32)\n",
    "    \n",
    "    # Model specific parameters\n",
    "    m = 1\n",
    "    N_tot = 1\n",
    "    f = gb_site_fraction(R_G=R_G, gb_width=GB_thickness) \n",
    "    fi = f * m/N_tot\n",
    "    fg = fi / f \n",
    "    x_hat_ki = gb_conc \n",
    "    x_global = (1 - f) * x_bulk + fi * x_hat_ki\n",
    "    x_hat_sum = fi * x_hat_ki\n",
    "    x_bulk_start = x_bulk \n",
    "\n",
    "\n",
    "    # Starting value for optimization\n",
    "    lamda = 0.001\n",
    "\n",
    "    def obj_func(lamda, Rg_T, x_hat_sum):\n",
    "        \n",
    "        nom = np.exp( -(E - lamda) / Rg_T)\n",
    "        nom = np.clip(nom, a_min=None, a_max=1e300)  \n",
    "\n",
    "        denom = 1 + np.exp( -(E - lamda) / Rg_T)\n",
    "\n",
    "        xk_i_hat_temp = nom/denom \n",
    "        xk_hat_temp = fi * xk_i_hat_temp \n",
    "\n",
    "        \n",
    "        abs_difference = np.abs(xk_hat_temp - x_hat_sum) \n",
    "        return abs_difference\n",
    "    \n",
    "    \n",
    "    options = {'disp': False, 'xatol': accuracy}\n",
    "\n",
    "\n",
    "    for indx in range(len(temperatures)):\n",
    "\n",
    "        Rg_T = Rg_Ts[indx]\n",
    "        \n",
    "        D = diffusion_coefficients[indx]\n",
    "        \n",
    "        # Perform minimization\n",
    "        result_value = 1\n",
    "        rv_i = 0\n",
    "        while abs(result_value) > accuracy: \n",
    "            # Optimization using Nelder-Mead algorithm\n",
    "            result = minimize(obj_func, lamda, args=(Rg_T, x_hat_sum), method=\"Nelder-Mead\", options=options)\n",
    "            new_lamda = result.x\n",
    "            lamda = new_lamda\n",
    "            result_value = result.fun\n",
    "            rv_i += 1\n",
    "            if rv_i > 10: # for checking, 10 is guessed\n",
    "                print(result_value)\n",
    "                break\n",
    "        \n",
    "        \n",
    "        nom = np.exp( -(E - lamda) / Rg_T)\n",
    "        nom = np.clip(nom, a_min=None, a_max=1e300)  \n",
    "\n",
    "        denom = 1 + np.exp( -(E - lamda) / Rg_T)\n",
    "\n",
    "        x_hat_ki = nom/denom\n",
    "        \n",
    "        gb_concs[indx] = x_hat_ki * fg\n",
    "        \n",
    "\n",
    "        nom_ln = 1 - x_bulk\n",
    "        denom_ln = x_bulk\n",
    "        frac_ln = np.log(nom_ln/denom_ln)\n",
    "\n",
    "        lamda_frac = lamda/Rg_T\n",
    "\n",
    "        lhs = 15*x_bulk*D/(R_G**2)\n",
    "\n",
    "        dx_hat = (-frac_ln - lamda_frac) * lhs \n",
    "\n",
    "        if np.isnan(dx_hat).any():\n",
    "                    raise ValueError(\"NaN value encountered in rhs. Stopping calculation.\")\n",
    "\n",
    "        x_hat_sum = x_hat_sum + dx_hat * dt\n",
    "    \n",
    "        \n",
    "        x_bulk = (x_global - x_hat_sum) / (1-f)\n",
    "\n",
    "        ife[indx] = (x_hat_sum * fg - x_bulk_start)/A\n",
    "        \n",
    "    return gb_concs, ife"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./examples/cython/kinetics_annotated.pyx\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./examples/cython/kinetics_annotated.pyx \n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from heat_treatment_annotated import get_T_and_D\n",
    "\n",
    "# Calculate fraction of GB sites compared to all sites in the system\n",
    "def gb_site_fraction(R_G=100e-6, gb_width=8.4e-10):\n",
    "    V_G = R_G**3\n",
    "    V_GB = V_G - (R_G - gb_width)**3\n",
    "    return V_GB/V_G\n",
    "\n",
    "def kinetics_annotated(t_tot: int, dt: float, accuracy: float, Tstart: float, R_G: float, D0: float, dQ: float,\n",
    "                  x_bulk: float, GB_thickness: float, E: float, A: float, gb_conc: float, Tend=None, r=None, heat_treatment_type=\"linear\"):\n",
    "    \n",
    "    \n",
    "    R_g = (8.314 / (1.602 * 10 ** (-19))) / (6.022 * 10 ** (23))  # gas constant in eV/K --> Boltzmann constant\n",
    "    \n",
    "    temperatures, diffusion_coefficients = get_T_and_D(t_tot=t_tot, Tstart=Tstart, D0=D0, dQ=dQ, dt=dt, Tend=Tend, heat_treatment_type=heat_treatment_type, r=r)\n",
    "    Rg_Ts = temperatures * R_g\n",
    "\n",
    "    gb_concs = np.empty(shape=(len(temperatures), 1), dtype=np.float32)\n",
    "    ife = np.empty(shape=(len(temperatures), 1), dtype=np.float32)\n",
    "    \n",
    "    # Model specific parameters\n",
    "    m = 1\n",
    "    N_tot = 1\n",
    "    f = gb_site_fraction(R_G=R_G, gb_width=GB_thickness) \n",
    "    fi = f * m/N_tot\n",
    "    fg = fi / f \n",
    "    x_hat_ki = gb_conc \n",
    "    x_global = (1 - f) * x_bulk + fi * x_hat_ki\n",
    "    x_hat_sum = fi * x_hat_ki\n",
    "    x_bulk_start = x_bulk \n",
    "\n",
    "\n",
    "    # Starting value for optimization\n",
    "    lamda = 0.001\n",
    "\n",
    "    def obj_func(lamda, Rg_T, x_hat_sum):\n",
    "        \n",
    "        nom = np.exp( -(E - lamda) / Rg_T)\n",
    "        nom = np.clip(nom, a_min=None, a_max=1e300)  \n",
    "\n",
    "        denom = 1 + np.exp( -(E - lamda) / Rg_T)\n",
    "\n",
    "        xk_i_hat_temp = nom/denom \n",
    "        xk_hat_temp = fi * xk_i_hat_temp \n",
    "\n",
    "        \n",
    "        abs_difference = np.abs(xk_hat_temp - x_hat_sum) \n",
    "        return abs_difference\n",
    "    \n",
    "    \n",
    "    options = {'disp': False, 'xatol': accuracy}\n",
    "\n",
    "\n",
    "    for indx in range(len(temperatures)):\n",
    "\n",
    "        Rg_T = Rg_Ts[indx]\n",
    "        \n",
    "        D = diffusion_coefficients[indx]\n",
    "        \n",
    "        # Perform minimization\n",
    "        result_value = 1\n",
    "        rv_i = 0\n",
    "        while abs(result_value) > accuracy: \n",
    "            # Optimization using Nelder-Mead algorithm\n",
    "            result = minimize(obj_func, lamda, args=(Rg_T, x_hat_sum), method=\"Nelder-Mead\", options=options)\n",
    "            new_lamda = result.x\n",
    "            lamda = new_lamda\n",
    "            result_value = result.fun\n",
    "            rv_i += 1\n",
    "            if rv_i > 10: # for checking, 10 is guessed\n",
    "                print(result_value)\n",
    "                break\n",
    "        \n",
    "        \n",
    "        nom = np.exp( -(E - lamda) / Rg_T)\n",
    "        nom = np.clip(nom, a_min=None, a_max=1e300)  \n",
    "\n",
    "        denom = 1 + np.exp( -(E - lamda) / Rg_T)\n",
    "\n",
    "        x_hat_ki = nom/denom\n",
    "        \n",
    "        gb_concs[indx] = x_hat_ki * fg\n",
    "        \n",
    "\n",
    "        nom_ln = 1 - x_bulk\n",
    "        denom_ln = x_bulk\n",
    "        frac_ln = np.log(nom_ln/denom_ln)\n",
    "\n",
    "        lamda_frac = lamda/Rg_T\n",
    "\n",
    "        lhs = 15*x_bulk*D/(R_G**2)\n",
    "\n",
    "        dx_hat = (-frac_ln - lamda_frac) * lhs \n",
    "\n",
    "        if np.isnan(dx_hat).any():\n",
    "                    raise ValueError(\"NaN value encountered in rhs. Stopping calculation.\")\n",
    "\n",
    "        x_hat_sum = x_hat_sum + dx_hat * dt\n",
    "    \n",
    "        \n",
    "        x_bulk = (x_global - x_hat_sum) / (1-f)\n",
    "\n",
    "        ife[indx] = (x_hat_sum * fg - x_bulk_start)/A\n",
    "        \n",
    "    return gb_concs, ife"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cythonized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./examples/cython/kinetics_cythonized.pyx\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./examples/cython/kinetics_cythonized.pyx \n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from libc.math cimport exp, sqrt\n",
    "\n",
    "# Function declarations\n",
    "cdef np.ndarray[np.float32_t, ndim=1] isothermal(float Tstart, int t_tot, float dt):\n",
    "    cdef int n = int(t_tot / dt) + 1\n",
    "    cdef np.ndarray[np.float32_t, ndim=1] t_steps = np.zeros(n, dtype=np.float32)\n",
    "    cdef np.ndarray[np.float32_t, ndim=1] temperatures = np.zeros(n, dtype=np.float32)\n",
    "    cdef int i\n",
    "    for i in range(n):\n",
    "        t_steps[i] = i * dt\n",
    "        temperatures[i] = Tstart\n",
    "    return temperatures\n",
    "\n",
    "\n",
    "cdef np.ndarray[np.float32_t, ndim=1] linear_heat_treatment(float Tstart, float Tend, int t_tot, float dt):\n",
    "    cdef int n = int(t_tot / dt) + 1\n",
    "    cdef np.ndarray[np.float32_t, ndim=1] t_steps = np.zeros(n, dtype=np.float32)\n",
    "    cdef np.ndarray[np.float32_t, ndim=1] temperatures = np.zeros(n, dtype=np.float32)\n",
    "    cdef float k = (Tend - Tstart) / t_tot\n",
    "    cdef int i\n",
    "    for i in range(n):\n",
    "        t_steps[i] = i * dt\n",
    "        temperatures[i] = k * t_steps[i] + Tstart\n",
    "    return temperatures\n",
    "\n",
    "cdef np.ndarray[np.float32_t, ndim=1] newton_cooling(float Tstart, float Tend, int t_tot, float dt, float r):\n",
    "    cdef int n = int(t_tot / dt) + 1\n",
    "    cdef np.ndarray[np.float32_t, ndim=1] t_steps = np.zeros(n, dtype=np.float32)\n",
    "    cdef np.ndarray[np.float32_t, ndim=1] temperatures = np.zeros(n, dtype=np.float32)\n",
    "    cdef int i\n",
    "    for i in range(n):\n",
    "        t_steps[i] = i * dt\n",
    "        temperatures[i] = Tend + (Tstart - Tend) * exp(-r * sqrt(t_steps[i]))\n",
    "    return temperatures\n",
    "\n",
    "cdef np.ndarray[np.float32_t, ndim=1] diff_coef(float D0, float dQ, np.ndarray[np.float32_t, ndim=1] T, float kB):\n",
    "    cdef int n = T.shape[0]\n",
    "    cdef np.ndarray[np.float32_t, ndim=1] diffusion_coefficients = np.zeros(n, dtype=np.float32)\n",
    "    cdef int i\n",
    "    for i in range(n):\n",
    "        diffusion_coefficients[i] = D0 * exp(-dQ / (kB * T[i]))\n",
    "    return diffusion_coefficients\n",
    "\n",
    "cpdef tuple get_T_and_D(int t_tot, float Tstart, float D0, float dQ, float dt, float Tend=-1, str heat_treatment_type=\"iso\", float r=-1):\n",
    "    cdef np.ndarray[np.float32_t, ndim=1] temperatures, diffusion_coefficients\n",
    "    if heat_treatment_type == \"iso\":\n",
    "        temperatures = isothermal(Tstart=Tstart, t_tot=t_tot, dt=dt)\n",
    "    elif heat_treatment_type == \"linear\":\n",
    "        if Tend == -1:\n",
    "            raise ValueError(\"Tend must be provided for linear heat treatment.\")\n",
    "        temperatures = linear_heat_treatment(Tstart=Tstart, Tend=Tend, t_tot=t_tot, dt=dt)\n",
    "    elif heat_treatment_type == \"newton_cooling\":\n",
    "        if Tend == -1 or r == -1:\n",
    "            raise ValueError(\"Tend and r must be provided for Newton cooling heat treatment.\")\n",
    "        temperatures = newton_cooling(Tstart=Tstart, Tend=Tend, t_tot=t_tot, dt=dt, r=r)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid heat_treatment_type. Must be 'iso', 'linear', or 'newton_cooling'.\")\n",
    "\n",
    "    diffusion_coefficients = diff_coef(D0=D0, dQ=dQ, T=temperatures, kB=(8.314 / (1.602 * 10**(-19))) / (6.022 * 10**(23)))\n",
    "\n",
    "    return temperatures, diffusion_coefficients\n",
    "\n",
    "\n",
    "# Calculate fraction of GB sites compared to all sites in the system\n",
    "cdef double gb_site_fraction(double R_G=100e-6, double gb_width=8.4e-10):\n",
    "    cdef double V_G = R_G**3\n",
    "    cdef double V_GB = V_G - (R_G - gb_width)**3\n",
    "    return V_GB / V_G\n",
    "\n",
    "cdef double obj_func(double lamda, double Rg_T, double x_hat_sum, double fi, double E):\n",
    "    cdef double nom = np.exp(-(E - lamda) / Rg_T)\n",
    "    nom = np.clip(nom, a_min=None, a_max=1e300)\n",
    "    cdef double denom = 1 + np.exp(-(E - lamda) / Rg_T)\n",
    "    cdef double xk_i_hat_temp = nom / denom\n",
    "    cdef double xk_hat_temp = fi * xk_i_hat_temp\n",
    "    return abs(xk_hat_temp - x_hat_sum)\n",
    "\n",
    "cpdef tuple kinetics_cythonized(int t_tot, double dt, double accuracy, double Tstart, double R_G, double D0, double dQ,\n",
    "                            double x_bulk, double GB_thickness, double E, double A, double gb_conc, \n",
    "                            double Tend=-1, double r=-1, str heat_treatment_type=\"linear\"):\n",
    "    cdef double R_g = (8.314 / (1.602 * 10 ** (-19))) / (6.022 * 10 ** (23))\n",
    "    \n",
    "    cdef np.ndarray[np.float32_t, ndim=1] temperatures, diffusion_coefficients, gb_concs, ife\n",
    "    temperatures, diffusion_coefficients = get_T_and_D(t_tot, Tstart, D0, dQ, dt, Tend, heat_treatment_type, r)\n",
    "    \n",
    "    cdef int len_temp = len(temperatures)\n",
    "    gb_concs = np.empty(len_temp, dtype=np.float32)\n",
    "    ife = np.empty(len_temp, dtype=np.float32)\n",
    "    \n",
    "    cdef np.ndarray[np.float32_t, ndim=1] Rg_Ts = temperatures * R_g\n",
    "    cdef np.ndarray[np.float32_t, ndim=1] diff_coefs = diffusion_coefficients\n",
    "    \n",
    "    cdef double m = 1\n",
    "    cdef double N_tot = 1\n",
    "    cdef double f = gb_site_fraction(R_G, GB_thickness)\n",
    "    cdef double fi = f * m / N_tot\n",
    "    cdef double fg = fi / f\n",
    "    cdef double x_hat_ki = gb_conc\n",
    "    cdef double x_global = (1 - f) * x_bulk + fi * x_hat_ki\n",
    "    cdef double x_hat_sum = fi * x_hat_ki\n",
    "    cdef double x_bulk_start = x_bulk\n",
    "\n",
    "    cdef double lamda = 0.001\n",
    "\n",
    "    cdef int indx\n",
    "    cdef double Rg_T, D, result_value, new_lamda, nom, denom, nom_ln, denom_ln, frac_ln, lamda_frac, lhs, dx_hat\n",
    "\n",
    "    for indx in range(len_temp):\n",
    "        Rg_T = Rg_Ts[indx]\n",
    "        D = diff_coefs[indx]\n",
    "        \n",
    "        result_value = 1\n",
    "        while abs(result_value) > accuracy:\n",
    "            result = minimize(obj_func, lamda, args=(Rg_T, x_hat_sum, fi, E), method=\"Nelder-Mead\", options={'disp': False, 'xatol': accuracy})\n",
    "            new_lamda = result.x[0]\n",
    "            lamda = new_lamda\n",
    "            result_value = result.fun\n",
    "            if result_value < accuracy:\n",
    "                break\n",
    "        \n",
    "        nom = exp(-(E - lamda) / Rg_T)\n",
    "        nom = max(nom, 1e-300)  # Use max instead of np.clip for Cython\n",
    "        denom = 1 + exp(-(E - lamda) / Rg_T)\n",
    "        x_hat_ki = nom / denom\n",
    "        gb_concs[indx] = x_hat_ki * fg\n",
    "\n",
    "        nom_ln = 1 - x_bulk\n",
    "        denom_ln = x_bulk\n",
    "        frac_ln = np.log(nom_ln / denom_ln)\n",
    "        lamda_frac = lamda / Rg_T\n",
    "        lhs = 15 * x_bulk * D / (R_G**2)\n",
    "        dx_hat = (-frac_ln - lamda_frac) * lhs\n",
    "        \n",
    "        if np.isnan(dx_hat).any():\n",
    "            raise ValueError(\"NaN value encountered in rhs. Stopping calculation.\")\n",
    "        \n",
    "        x_hat_sum += dx_hat * dt\n",
    "        x_bulk = (x_global - x_hat_sum) / (1 - f)\n",
    "        ife[indx] = (x_hat_sum * fg - x_bulk_start) / A\n",
    "        \n",
    "    return gb_concs, ife\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./examples/cython/setup_kinetics.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./examples/cython/setup_kinetics.py\n",
    "from Cython.Build import cythonize\n",
    "from setuptools import setup, Extension\n",
    "import numpy as np\n",
    "\n",
    "extensions = [\n",
    "    Extension(\n",
    "        \"kinetics_annotated\",\n",
    "        [\"./examples/cython/kinetics_annotated.pyx\"],\n",
    "        include_dirs=[np.get_include()],  # Include the NumPy headers\n",
    "    ),\n",
    "    Extension(\n",
    "        \"kinetics_cythonized\",\n",
    "        [\"./examples/cython/kinetics_cythonized.pyx\"],\n",
    "        include_dirs=[np.get_include()],  # Include the NumPy headers\n",
    "    )\n",
    "]\n",
    "\n",
    "setup(\n",
    "    ext_modules=cythonize(\n",
    "        extensions,\n",
    "        compiler_directives={'language_level': \"3\"}  # Ensure Cython uses Python 3 syntax\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling ./examples/cython/kinetics_annotated.pyx because it changed.\n",
      "Compiling ./examples/cython/kinetics_cythonized.pyx because it changed.\n",
      "[1/2] Cythonizing ./examples/cython/kinetics_annotated.pyx\n",
      "[2/2] Cythonizing ./examples/cython/kinetics_cythonized.pyx\n",
      "running build_ext\n",
      "building 'kinetics_annotated' extension\n",
      "gcc -pthread -B /home/amin/anaconda3/envs/pycalphad/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/amin/anaconda3/envs/pycalphad/include -fPIC -O2 -isystem /home/amin/anaconda3/envs/pycalphad/include -fPIC -I/home/amin/anaconda3/envs/pycalphad/lib/python3.11/site-packages/numpy/core/include -I/home/amin/anaconda3/envs/pycalphad/include/python3.11 -c ./examples/cython/kinetics_annotated.c -o build/temp.linux-x86_64-cpython-311/./examples/cython/kinetics_annotated.o\n",
      "gcc -pthread -B /home/amin/anaconda3/envs/pycalphad/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/home/amin/anaconda3/envs/pycalphad/lib -Wl,-rpath-link,/home/amin/anaconda3/envs/pycalphad/lib -L/home/amin/anaconda3/envs/pycalphad/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/home/amin/anaconda3/envs/pycalphad/lib -Wl,-rpath-link,/home/amin/anaconda3/envs/pycalphad/lib -L/home/amin/anaconda3/envs/pycalphad/lib build/temp.linux-x86_64-cpython-311/./examples/cython/kinetics_annotated.o -o ./examples/cython/kinetics_annotated.cpython-311-x86_64-linux-gnu.so\n",
      "building 'kinetics_cythonized' extension\n",
      "gcc -pthread -B /home/amin/anaconda3/envs/pycalphad/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/amin/anaconda3/envs/pycalphad/include -fPIC -O2 -isystem /home/amin/anaconda3/envs/pycalphad/include -fPIC -I/home/amin/anaconda3/envs/pycalphad/lib/python3.11/site-packages/numpy/core/include -I/home/amin/anaconda3/envs/pycalphad/include/python3.11 -c ./examples/cython/kinetics_cythonized.c -o build/temp.linux-x86_64-cpython-311/./examples/cython/kinetics_cythonized.o\n",
      "In file included from \u001b[01m\u001b[K/home/amin/anaconda3/envs/pycalphad/lib/python3.11/site-packages/numpy/core/include/numpy/ndarraytypes.h:1929\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/amin/anaconda3/envs/pycalphad/lib/python3.11/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/amin/anaconda3/envs/pycalphad/lib/python3.11/site-packages/numpy/core/include/numpy/arrayobject.h:5\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./examples/cython/kinetics_cythonized.c:1249\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/amin/anaconda3/envs/pycalphad/lib/python3.11/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wcpp\u0007-Wcpp\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
      "gcc -pthread -B /home/amin/anaconda3/envs/pycalphad/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/home/amin/anaconda3/envs/pycalphad/lib -Wl,-rpath-link,/home/amin/anaconda3/envs/pycalphad/lib -L/home/amin/anaconda3/envs/pycalphad/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/home/amin/anaconda3/envs/pycalphad/lib -Wl,-rpath-link,/home/amin/anaconda3/envs/pycalphad/lib -L/home/amin/anaconda3/envs/pycalphad/lib build/temp.linux-x86_64-cpython-311/./examples/cython/kinetics_cythonized.o -o ./examples/cython/kinetics_cythonized.cpython-311-x86_64-linux-gnu.so\n"
     ]
    }
   ],
   "source": [
    "!python3 ./examples/cython/setup_kinetics.py build_ext -b ./examples/cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./examples/cython/execute_kinetics.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./examples/cython/execute_kinetics.py\n",
    "from timeit import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the parameters\n",
    "params = {\n",
    "    't_tot': 3600,\n",
    "    'dt': 0.1,\n",
    "    'accuracy': 1e-6,\n",
    "    'Tstart': 2000.0,\n",
    "    'R_G': 100e-6,\n",
    "    'dQ': 2.355,\n",
    "    'D0': 3.3e-5,\n",
    "    'x_bulk': 0.0004942285667828602,\n",
    "    'GB_thickness': 8.4e-10,\n",
    "    'E': -1.2972039599999334,\n",
    "    'A': 0.27920385353982713,\n",
    "    'gb_conc': 0.47854028493419043,\n",
    "    'Tend': 500.0,\n",
    "    'heat_treatment_type': 'linear',\n",
    "    'r': -1.0\n",
    "}\n",
    "\n",
    "\n",
    "t1 = timeit(\"kinetics_python(**params)\",\n",
    "            setup=\"from kinetics_python import kinetics_python; from __main__ import params\",\n",
    "            number=1)\n",
    "\n",
    "t2 = timeit(\"kinetics_annotated(**params)\",\n",
    "            setup=\"from kinetics_annotated import kinetics_annotated; from __main__ import params\",\n",
    "            number=1)\n",
    "\n",
    "t3 = timeit(\"kinetics_cythonized(**params)\",\n",
    "            setup=\"from kinetics_cythonized import kinetics_cythonized; from __main__ import params\",\n",
    "            number=1)\n",
    "\n",
    "print(f\"Python: Time for get kinetics: {t1} seconds for 1 run\")\n",
    "print(f\"Annotated: Time for get kinetics: {t2} seconds for 1 run\")\n",
    "print(f\"Cythonized: Time for get kinetics: {t3} seconds for 1 run\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: Time for get kinetics: 33.966041580999445 seconds for 1 run\n",
      "Annotated: Time for get kinetics: 34.67176866099908 seconds for 1 run\n",
      "Cythonized: Time for get kinetics: 28.32787865800492 seconds for 1 run\n"
     ]
    }
   ],
   "source": [
    "!python3 ./examples/cython/execute_kinetics.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we could improve the speed a little bit (approx. by 5 and a 1/2 sec). We also see that the annotated version is not faster than the pure python code. This strongly depends on the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we have seen that the minimization takes most of the time. In addition, scipy uses a Wrapper which takes also substantial time. So in order to make the code way faster, we need to write our own minimizer. The Nelder-Mead method is straight forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nelder Mead method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./examples/cython/nelder_mead_python.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./examples/cython/nelder_mead_python.py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def nelder_mead_python(func, x_start,\n",
    "                step=0.1, no_improve_thr=10e-6,\n",
    "                no_improv_break=10, max_iter=0,\n",
    "                alpha=1., gamma=2., rho=-0.5, sigma=0.5):\n",
    "    \"\"\"\n",
    "    Nelder-Mead algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    func : callable\n",
    "        The objective function to be minimized.\n",
    "    x_start : numpy array\n",
    "        Initial guess for the minimizer.\n",
    "    step : float\n",
    "        Look-around radius to initialize the simplex.\n",
    "    no_improve_thr : float\n",
    "        Threshold for improvement (default: 10e-6).\n",
    "    no_improv_break : int\n",
    "        Number of iterations with no improvement to break (default: 10).\n",
    "    max_iter : int\n",
    "        Maximum number of iterations (default: 0 for infinite).\n",
    "    alpha : float\n",
    "        Reflection coefficient (default: 1.0).\n",
    "    gamma : float\n",
    "        Expansion coefficient (default: 2.0).\n",
    "    rho : float\n",
    "        Contraction coefficient (default: -0.5).\n",
    "    sigma : float\n",
    "        Shrink coefficient (default: 0.5).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    best : numpy array\n",
    "        Best parameter array found.\n",
    "    best_score : float\n",
    "        Score of the best parameter array.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize variables\n",
    "    dim = len(x_start)\n",
    "    prev_best = func(x_start)\n",
    "    no_improve = 0\n",
    "    res = [[x_start, prev_best]]\n",
    "\n",
    "    # Initialize simplex\n",
    "    for i in range(dim):\n",
    "        x = np.copy(x_start)\n",
    "        x[i] = x[i] + step\n",
    "        score = func(x)\n",
    "        res.append([x, score])\n",
    "\n",
    "    # Sort\n",
    "    res.sort(key=lambda x: x[1])\n",
    "    best = res[0][0]\n",
    "    best_score = res[0][1]\n",
    "\n",
    "    iterations = 0\n",
    "\n",
    "    while True:\n",
    "        # Break conditions\n",
    "        if max_iter and iterations >= max_iter:\n",
    "            break\n",
    "        iterations += 1\n",
    "\n",
    "        # Order\n",
    "        res.sort(key=lambda x: x[1])\n",
    "        best = res[0][0]\n",
    "        best_score = res[0][1]\n",
    "\n",
    "        # Track improvement\n",
    "        if best_score < prev_best - no_improve_thr:\n",
    "            no_improve = 0\n",
    "            prev_best = best_score\n",
    "        else:\n",
    "            no_improve += 1\n",
    "\n",
    "        if no_improve >= no_improv_break:\n",
    "            break\n",
    "\n",
    "        # Centroid\n",
    "        x0 = np.zeros(dim)\n",
    "        for tup in res[:-1]:\n",
    "            x0 += tup[0]\n",
    "        x0 /= (len(res) - 1)\n",
    "\n",
    "        # Reflection\n",
    "        xr = x0 + alpha * (x0 - res[-1][0])\n",
    "        rscore = func(xr)\n",
    "        if res[0][1] <= rscore < res[-2][1]:\n",
    "            res[-1] = [xr, rscore]\n",
    "            continue\n",
    "\n",
    "        # Expansion\n",
    "        if rscore < res[0][1]:\n",
    "            xe = x0 + gamma * (x0 - res[-1][0])\n",
    "            escore = func(xe)\n",
    "            if escore < rscore:\n",
    "                res[-1] = [xe, escore]\n",
    "                continue\n",
    "            else:\n",
    "                res[-1] = [xr, rscore]\n",
    "                continue\n",
    "\n",
    "        # Contraction\n",
    "        xc = x0 + rho * (x0 - res[-1][0])\n",
    "        cscore = func(xc)\n",
    "        if cscore < res[-1][1]:\n",
    "            res[-1] = [xc, cscore]\n",
    "            continue\n",
    "\n",
    "        # Reduction\n",
    "        x1 = res[0][0]\n",
    "        nres = []\n",
    "        for tup in res:\n",
    "            redx = x1 + sigma * (tup[0] - x1)\n",
    "            score = func(redx)\n",
    "            nres.append([redx, score])\n",
    "        res = nres\n",
    "\n",
    "    return best, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter: [0.1 0.  0.  0.  0. ]\n",
      "Best score: 3.8200000000000003\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    def rosenbrock(x):\n",
    "        return sum(100.0*(x[1:] - x[:-1]**2.0)**2.0 + (1 - x[:-1])**2.0)\n",
    "    \n",
    "    x_start = np.array([0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "    result, score = nelder_mead(rosenbrock, x_start)\n",
    "    print(f\"Best parameter: {result}\")\n",
    "    print(f\"Best score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.98 ms ± 260 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "result, score = nelder_mead(rosenbrock, x_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.11 ms ± 216 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100 \n",
    "result = minimize(fun=rosenbrock, x0=x_start, method=\"Nelder-Mead\", options={'xatol': 10e-6})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Nelder-Mead algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    func : callable\n",
    "        The objective function to be minimized.\n",
    "    x_start : numpy array\n",
    "        Initial guess for the minimizer.\n",
    "    step : float\n",
    "        Look-around radius to initialize the simplex.\n",
    "    no_improve_thr : float\n",
    "        Threshold for improvement (default: 10e-6).\n",
    "    no_improv_break : int\n",
    "        Number of iterations with no improvement to break (default: 10).\n",
    "    max_iter : int\n",
    "        Maximum number of iterations (default: 0 for infinite).\n",
    "    alpha : float\n",
    "        Reflection coefficient (default: 1.0).\n",
    "    gamma : float\n",
    "        Expansion coefficient (default: 2.0).\n",
    "    rho : float\n",
    "        Contraction coefficient (default: -0.5).\n",
    "    sigma : float\n",
    "        Shrink coefficient (default: 0.5).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    best : numpy array\n",
    "        Best parameter array found.\n",
    "    best_score : float\n",
    "        Score of the best parameter array.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./examples/cython/nelder_mead_cython.pyx\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./examples/cython/nelder_mead_cython.pyx\n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from libc.math cimport exp, sqrt\n",
    "\n",
    "cdef tuple nelder_mead_cython(func, double[:] x_start,\n",
    "                double step, double no_improve_thr,\n",
    "                int no_improv_break, int max_iter,\n",
    "                double alpha, double gamma, double rho, double sigma,\n",
    "                double Rg_T, double x_hat_sum, double fi, double E):\n",
    "    \n",
    "    # Initialize variables\n",
    "    cdef int dim = x_start.shape[0]\n",
    "    cdef double prev_best = func(x_start, Rg_T, x_hat_sum, fi, E)\n",
    "    cdef int no_improve = 0\n",
    "    cdef list res = [[np.copy(x_start), prev_best]]\n",
    "    \n",
    "    cdef double[:] best\n",
    "    cdef double best_score\n",
    "\n",
    "    # Initialize simplex\n",
    "    cdef double[:] x\n",
    "    for i in range(dim):\n",
    "        x = np.copy(x_start)\n",
    "        x[i] = x_start[i] + step\n",
    "        score = func(x, Rg_T, x_hat_sum, fi, E)\n",
    "        res.append([x, score])\n",
    "\n",
    "    # Sort\n",
    "    res.sort(key=lambda x: x[1])\n",
    "    best = res[0][0]\n",
    "    best_score = res[0][1]\n",
    "\n",
    "    cdef int iterations = 0\n",
    "\n",
    "    while True:\n",
    "        # Break conditions\n",
    "        if max_iter and iterations >= max_iter:\n",
    "            break\n",
    "        iterations += 1\n",
    "\n",
    "        # Order\n",
    "        res.sort(key=lambda x: x[1])\n",
    "        best = res[0][0]\n",
    "        best_score = res[0][1]\n",
    "\n",
    "        # Track improvement\n",
    "        if best_score < prev_best - no_improve_thr:\n",
    "            no_improve = 0\n",
    "            prev_best = best_score\n",
    "        else:\n",
    "            no_improve += 1\n",
    "\n",
    "        if no_improve >= no_improv_break:\n",
    "            break\n",
    "\n",
    "        # Centroid\n",
    "        x0 = np.zeros(dim)\n",
    "        for tup in res[:-1]:\n",
    "            x0 += tup[0]\n",
    "        x0 /= (len(res) - 1)\n",
    "\n",
    "        # Reflection\n",
    "        xr = x0 + alpha * (x0 - res[-1][0])\n",
    "        rscore = func(xr, Rg_T, x_hat_sum, fi, E)\n",
    "        if res[0][1] <= rscore < res[-2][1]:\n",
    "            res[-1] = [xr, rscore]\n",
    "            continue\n",
    "\n",
    "        # Expansion\n",
    "        if rscore < res[0][1]:\n",
    "            xe = x0 + gamma * (x0 - res[-1][0])\n",
    "            escore = func(xe, Rg_T, x_hat_sum, fi, E)\n",
    "            if escore < rscore:\n",
    "                res[-1] = [xe, escore]\n",
    "                continue\n",
    "            else:\n",
    "                res[-1] = [xr, rscore]\n",
    "                continue\n",
    "\n",
    "        # Contraction\n",
    "        xc = x0 + rho * (x0 - res[-1][0])\n",
    "        cscore = func(xc, Rg_T, x_hat_sum, fi, E)\n",
    "        if cscore < res[-1][1]:\n",
    "            res[-1] = [xc, cscore]\n",
    "            continue\n",
    "\n",
    "        # Reduction\n",
    "        x1 = res[0][0]\n",
    "        nres = []\n",
    "        for tup in res:\n",
    "            redx = x1 + sigma * (tup[0] - x1)\n",
    "            score = func(redx, Rg_T, x_hat_sum, fi, E)\n",
    "            nres.append([redx, score])\n",
    "        res = nres\n",
    "\n",
    "    return best, best_score\n",
    "\n",
    "\n",
    "cdef double[:] isothermal(float Tstart, int t_tot, float dt):\n",
    "    cdef int n = int(t_tot / dt) + 1\n",
    "    cdef double[:] temperatures = np.zeros(n, dtype=np.float32)\n",
    "    cdef int i\n",
    "    for i in range(n):\n",
    "        temperatures[i] = Tstart\n",
    "    return temperatures\n",
    "\n",
    "cdef double[:] linear_heat_treatment(float Tstart, float Tend, int t_tot, float dt):\n",
    "    cdef int n = int(t_tot / dt) + 1\n",
    "    cdef double[:] temperatures = np.zeros(n, dtype=np.float64)\n",
    "    cdef float slope = (Tend - Tstart) / t_tot\n",
    "    cdef int i\n",
    "    for i in range(n):\n",
    "        temperatures[i] = Tstart + slope * (i * dt)\n",
    "    return temperatures\n",
    "\n",
    "cdef double[:] newton_cooling(float Tstart, float Tend, int t_tot, float dt, float r):\n",
    "    cdef int n = int(t_tot / dt) + 1\n",
    "    cdef double[:] temperatures = np.zeros(n, dtype=np.float32)\n",
    "    cdef int i\n",
    "    for i in range(n):\n",
    "        temperatures[i] = Tend + (Tstart - Tend) * exp(-r * sqrt(i * dt))\n",
    "    return temperatures\n",
    "\n",
    "\n",
    "cdef double[:] diff_coef(float D0, float dQ, double[:] T, float kB):\n",
    "    cdef int n = T.shape[0]\n",
    "    cdef double[:] diffusion_coefficients = np.zeros(n, dtype=np.float64)\n",
    "    cdef int i\n",
    "    for i in range(n):\n",
    "        diffusion_coefficients[i] = D0 * exp(-dQ / (kB * T[i]))\n",
    "    return diffusion_coefficients\n",
    "\n",
    "cpdef tuple get_T_and_D(int t_tot, float Tstart, float D0, float dQ, float dt, float Tend=-1, str heat_treatment_type=\"iso\", float r=-1):\n",
    "    cdef double[:] temperatures, diffusion_coefficients\n",
    "    if heat_treatment_type == \"iso\":\n",
    "        temperatures = isothermal(Tstart=Tstart, t_tot=t_tot, dt=dt)\n",
    "    elif heat_treatment_type == \"linear\":\n",
    "        if Tend == -1:\n",
    "            raise ValueError(\"Tend must be provided for linear heat treatment.\")\n",
    "        temperatures = linear_heat_treatment(Tstart=Tstart, Tend=Tend, t_tot=t_tot, dt=dt)\n",
    "    elif heat_treatment_type == \"newton_cooling\":\n",
    "        if Tend == -1 or r == -1:\n",
    "            raise ValueError(\"Tend and r must be provided for Newton cooling heat treatment.\")\n",
    "        temperatures = newton_cooling(Tstart=Tstart, Tend=Tend, t_tot=t_tot, dt=dt, r=r)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid heat_treatment_type. Must be 'iso', 'linear', or 'newton_cooling'.\")\n",
    "\n",
    "    diffusion_coefficients = diff_coef(D0=D0, dQ=dQ, T=temperatures, kB=(8.314 / (1.602 * 10**(-19))) / (6.022 * 10**(23)))\n",
    "\n",
    "    return temperatures, diffusion_coefficients\n",
    "\n",
    "\n",
    "# Calculate fraction of GB sites compared to all sites in the system\n",
    "cdef double gb_site_fraction(double R_G=100e-6, double gb_width=8.4e-10):\n",
    "    cdef double V_G = R_G**3\n",
    "    cdef double V_GB = V_G - (R_G - gb_width)**3\n",
    "    return V_GB / V_G\n",
    "\n",
    "cdef double obj_func(double[:] lamda, double Rg_T, double x_hat_sum, double fi, double E):\n",
    "    cdef double nom = exp(-(E - lamda[0]) / Rg_T)\n",
    "    nom = min(nom, 1e300)  # Use min instead of np.clip for Cython\n",
    "    cdef double denom = 1 + exp(-(E - lamda[0]) / Rg_T)\n",
    "    cdef double xk_i_hat_temp = nom / denom\n",
    "    cdef double xk_hat_temp = fi * xk_i_hat_temp\n",
    "    return abs(xk_hat_temp - x_hat_sum)\n",
    "\n",
    "\n",
    "cdef double wrapped_obj_func(double[:] lamda, double Rg_T, double x_hat_sum, double fi, double E):\n",
    "    return obj_func(lamda, Rg_T, x_hat_sum, fi, E)\n",
    "\n",
    "\n",
    "cpdef tuple kinetics_cythonized_nm(int t_tot, double dt, double accuracy, double Tstart, double R_G, double D0, double dQ,\n",
    "                                   double x_bulk, double GB_thickness, double E, double A, double gb_conc,\n",
    "                                   double Tend=-1, double r=-1, str heat_treatment_type=\"linear\"):\n",
    "    # Minimizer defaults\n",
    "    cdef double step = 0.1\n",
    "    cdef double no_improve_thr = 10e-6\n",
    "    cdef int no_improv_break = 10\n",
    "    cdef int max_iter = 0\n",
    "    cdef double alpha = 1.\n",
    "    cdef double gamma = 2.\n",
    "    cdef double rho = -0.5\n",
    "    cdef double sigma = 0.5\n",
    "\n",
    "    cdef double R_g = (8.314 / (1.602 * 10 ** (-19))) / (6.022 * 10 ** (23))\n",
    "\n",
    "    cdef double[:] temperatures, diffusion_coefficients, gb_concs, ife\n",
    "    temperatures, diffusion_coefficients = get_T_and_D(t_tot, Tstart, D0, dQ, dt, Tend, heat_treatment_type, r)\n",
    "\n",
    "    cdef int len_temp = temperatures.shape[0]\n",
    "    gb_concs = np.empty(len_temp, dtype=np.float64)\n",
    "    ife = np.empty(len_temp, dtype=np.float64)\n",
    "\n",
    "    cdef double[:] Rg_Ts = np.array(temperatures) * R_g\n",
    "    cdef double[:] diff_coefs = diffusion_coefficients\n",
    "\n",
    "    cdef double m = 1\n",
    "    cdef double N_tot = 1\n",
    "    cdef double f = gb_site_fraction(R_G, GB_thickness)\n",
    "    cdef double fi = f * m / N_tot\n",
    "    cdef double fg = fi / f\n",
    "    cdef double x_hat_ki = gb_conc\n",
    "    cdef double x_global = (1 - f) * x_bulk + fi * x_hat_ki\n",
    "    cdef double x_hat_sum = fi * x_hat_ki\n",
    "    cdef double x_bulk_start = x_bulk\n",
    "\n",
    "    cdef double[:] lamda = np.array([0.001], dtype=np.float64)\n",
    "    cdef double[:] new_lamda\n",
    "\n",
    "    cdef int indx\n",
    "    cdef double Rg_T, D, result_value, nom, denom, nom_ln, denom_ln, frac_ln, lamda_frac, lhs, dx_hat\n",
    "\n",
    "    for indx in range(len_temp):\n",
    "        Rg_T = Rg_Ts[indx]\n",
    "        D = diff_coefs[indx]\n",
    "\n",
    "        # Use wrapped_obj_func instead of lambda\n",
    "        result = nelder_mead_cython(wrapped_obj_func, lamda,\n",
    "                                    step, no_improve_thr, no_improv_break, max_iter, alpha, gamma, rho, sigma, Rg_T, x_hat_sum, fi, E)\n",
    "        new_lamda = result[0]\n",
    "        lamda = new_lamda\n",
    "        result_value = result[-1]  # This value is not used, consider removing it if unnecessary\n",
    "\n",
    "        nom = exp(-(E - lamda[0]) / Rg_T)\n",
    "        nom = max(nom, 1e-300)  # Use max instead of np.clip for Cython\n",
    "        denom = 1 + exp(-(E - lamda[0]) / Rg_T)\n",
    "        x_hat_ki = nom / denom\n",
    "        gb_concs[indx] = x_hat_ki * fg\n",
    "\n",
    "        nom_ln = 1 - x_bulk\n",
    "        denom_ln = x_bulk\n",
    "        frac_ln = np.log(nom_ln / denom_ln)\n",
    "        lamda_frac = lamda[0] / Rg_T\n",
    "        lhs = 15 * x_bulk * D / (R_G**2)\n",
    "        dx_hat = (-frac_ln - lamda_frac) * lhs\n",
    "\n",
    "        if np.isnan(dx_hat).any():\n",
    "            raise ValueError(\"NaN value encountered in dx_hat. Stopping calculation.\")\n",
    "\n",
    "        x_hat_sum += dx_hat * dt\n",
    "        x_bulk = (x_global - x_hat_sum) / (1 - f)\n",
    "        ife[indx] = (x_hat_sum * fg - x_bulk_start) / A\n",
    "\n",
    "    return gb_concs, ife\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./examples/cython/setup_kinetics_nm.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./examples/cython/setup_kinetics_nm.py\n",
    "from Cython.Build import cythonize\n",
    "from setuptools import setup, Extension\n",
    "import numpy as np\n",
    "\n",
    "extensions = [\n",
    "    Extension(\n",
    "        \"kinetics_cythonized_nm\",\n",
    "        [\"./examples/cython/nelder_mead_cython.pyx\"],\n",
    "        include_dirs=[np.get_include()],  # Include the NumPy headers\n",
    "    )\n",
    "]\n",
    "\n",
    "setup(\n",
    "    ext_modules=cythonize(\n",
    "        extensions,\n",
    "        compiler_directives={'language_level': \"3\"}  # Ensure Cython uses Python 3 syntax\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling ./examples/cython/nelder_mead_cython.pyx because it changed.\n",
      "[1/1] Cythonizing ./examples/cython/nelder_mead_cython.pyx\n",
      "running build_ext\n",
      "building 'kinetics_cythonized_nm' extension\n",
      "gcc -pthread -B /home/amin/anaconda3/envs/pycalphad/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/amin/anaconda3/envs/pycalphad/include -fPIC -O2 -isystem /home/amin/anaconda3/envs/pycalphad/include -fPIC -I/home/amin/anaconda3/envs/pycalphad/lib/python3.11/site-packages/numpy/core/include -I/home/amin/anaconda3/envs/pycalphad/include/python3.11 -c ./examples/cython/nelder_mead_cython.c -o build/temp.linux-x86_64-cpython-311/./examples/cython/nelder_mead_cython.o\n",
      "In file included from \u001b[01m\u001b[K/home/amin/anaconda3/envs/pycalphad/lib/python3.11/site-packages/numpy/core/include/numpy/ndarraytypes.h:1929\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/amin/anaconda3/envs/pycalphad/lib/python3.11/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/amin/anaconda3/envs/pycalphad/lib/python3.11/site-packages/numpy/core/include/numpy/arrayobject.h:5\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./examples/cython/nelder_mead_cython.c:1249\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/amin/anaconda3/envs/pycalphad/lib/python3.11/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wcpp\u0007-Wcpp\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
      "gcc -pthread -B /home/amin/anaconda3/envs/pycalphad/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/home/amin/anaconda3/envs/pycalphad/lib -Wl,-rpath-link,/home/amin/anaconda3/envs/pycalphad/lib -L/home/amin/anaconda3/envs/pycalphad/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/home/amin/anaconda3/envs/pycalphad/lib -Wl,-rpath-link,/home/amin/anaconda3/envs/pycalphad/lib -L/home/amin/anaconda3/envs/pycalphad/lib build/temp.linux-x86_64-cpython-311/./examples/cython/nelder_mead_cython.o -o ./examples/cython/kinetics_cythonized_nm.cpython-311-x86_64-linux-gnu.so\n"
     ]
    }
   ],
   "source": [
    "!python3 ./examples/cython/setup_kinetics_nm.py build_ext -b ./examples/cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./examples/cython/execute_kinetics_nm.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./examples/cython/execute_kinetics_nm.py\n",
    "from timeit import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the parameters\n",
    "params = {\n",
    "    't_tot': 3600,\n",
    "    'dt': 0.1,\n",
    "    'accuracy': 1e-6,\n",
    "    'Tstart': 2000.0,\n",
    "    'R_G': 100e-6,\n",
    "    'dQ': 2.355,\n",
    "    'D0': 3.3e-5,\n",
    "    'x_bulk': 0.0004942285667828602,\n",
    "    'GB_thickness': 8.4e-10,\n",
    "    'E': -1.2972039599999334,\n",
    "    'A': 0.27920385353982713,\n",
    "    'gb_conc': 0.47854028493419043,\n",
    "    'Tend': 500.0,\n",
    "    'heat_treatment_type': 'linear',\n",
    "    'r': -1.0\n",
    "}\n",
    "\n",
    "\n",
    "t1 = timeit(\"kinetics_python(**params)\",\n",
    "            setup=\"from kinetics_python import kinetics_python; from __main__ import params\",\n",
    "            number=1)\n",
    "\n",
    "t2 = timeit(\"kinetics_annotated(**params)\",\n",
    "            setup=\"from kinetics_annotated import kinetics_annotated; from __main__ import params\",\n",
    "            number=1)\n",
    "\n",
    "t3 = timeit(\"kinetics_cythonized(**params)\",\n",
    "            setup=\"from kinetics_cythonized import kinetics_cythonized; from __main__ import params\",\n",
    "            number=1)\n",
    "\n",
    "t4 = timeit(\"kinetics_cythonized_nm(**params)\",\n",
    "            setup=\"from kinetics_cythonized_nm import kinetics_cythonized_nm; from __main__ import params\",\n",
    "            number=1)\n",
    "print(f\"Python: Time for get kinetics: {t1} seconds for 1 run\")\n",
    "print(f\"Annotated: Time for get kinetics: {t2} seconds for 1 run\")\n",
    "print(f\"Cythonized: Time for get kinetics: {t3} seconds for 1 run\")\n",
    "print(f\"Cythonized and self written Nelder-Mead: Time for get kinetics: {t4} seconds for 1 run\")\n",
    "print(f\"Cythonized code with self written Nelder-Mead is {t1/t4} times faster than the originial python implementation using the scipy Nelder-Mead minimizer.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: Time for get kinetics: 35.228860638002516 seconds for 1 run\n",
      "Annotated: Time for get kinetics: 35.44929618499009 seconds for 1 run\n",
      "Cythonized: Time for get kinetics: 29.03622110300057 seconds for 1 run\n",
      "Cythonized and self written Nelder-Mead: Time for get kinetics: 3.564813242002856 seconds for 1 run\n",
      "Cythonized code with self written Nelder-Mead is 9.882386045617784 times faster than the originial python implementation using the scipy Nelder-Mead minimizer.\n"
     ]
    }
   ],
   "source": [
    "!python3 ./examples/cython/execute_kinetics_nm.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like an awesome achievement in terms of speed. The code is $\\approx$ 10 $\\times$ faster. Lets check if the results are still the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./examples/cython/execute_comparison_kinetics_nm.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./examples/cython/execute_comparison_kinetics_nm.py\n",
    "from timeit import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "from kinetics_cythonized_nm import kinetics_cythonized_nm\n",
    "from kinetics_python import kinetics_python\n",
    "import numpy as np\n",
    "params = {\n",
    "    't_tot': 3600,\n",
    "    'dt': 0.1,\n",
    "    'accuracy': 1e-6,\n",
    "    'Tstart': 2000.0,\n",
    "    'R_G': 100e-6,\n",
    "    'dQ': 2.355,\n",
    "    'D0': 3.3e-5,\n",
    "    'x_bulk': 0.0004942285667828602,\n",
    "    'GB_thickness': 8.4e-10,\n",
    "    'E': -1.2972039599999334,\n",
    "    'A': 0.27920385353982713,\n",
    "    'gb_conc': 0.47854028493419043,\n",
    "    'Tend': 500.0,\n",
    "    'heat_treatment_type': 'linear',\n",
    "    'r': -1.0\n",
    "}\n",
    "\n",
    "            \n",
    "results_python = kinetics_python(**params)\n",
    "gb_cython, ife_cython = kinetics_cythonized_nm(**params)\n",
    "\n",
    "\n",
    "plt.plot(results_python[0], color=\"red\",label=\"python\")\n",
    "plt.plot(np.array(gb_cython), color=\"green\",ls=\"--\",label=\"cython\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"comparison_python_cython.pdf\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ./examples/cython/execute_comparison_kinetics_nm.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is great! We obtain the same results as well. Can we go any faster?\n",
    "\n",
    "\n",
    "\n",
    "Yes we can and we should. We still have the option to parallelize the code. However, the Nelder-Mead minimization technique is serial. So we will not get much speed ups. Lets try a different minimizer, called **Particle Swarm Optimization** [PSO](https://en.wikipedia.org/wiki/Particle_swarm_optimization). In the context of the PSO a particle represents a candidate solution within the search space. Each particle has a position and a velocity, which are adjusted iteratively as the optimizitaion progresses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSO minimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./examples/cython/pso_python.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./examples/cython/pso_python.py\n",
    "import numpy as np\n",
    "\n",
    "class Particle:\n",
    "    def __init__(self, bounds):\n",
    "        self.position = np.array([np.random.uniform(low, high) for low, high in bounds])\n",
    "        self.velocity = np.array([np.random.uniform(-abs(high - low), abs(high - low)) for low, high in bounds])\n",
    "        self.best_position = self.position.copy()\n",
    "        self.best_score = float('inf')\n",
    "\n",
    "    def update_velocity(self, global_best_position, w, c1, c2):\n",
    "        r1, r2 = np.random.random(2)\n",
    "        cognitive = c1 * r1 * (self.best_position - self.position)\n",
    "        social = c2 * r2 * (global_best_position - self.position)\n",
    "        self.velocity = w * self.velocity + cognitive + social\n",
    "\n",
    "    def update_position(self, bounds):\n",
    "        self.position += self.velocity\n",
    "        # Ensure particle stays within bounds\n",
    "        for i in range(len(bounds)):\n",
    "            self.position[i] = np.clip(self.position[i], bounds[i][0], bounds[i][1])\n",
    "\n",
    "def pso(func, bounds, num_particles=30, max_iter=100, w=0.5, c1=1.0, c2=2.0, tol=1e-6, stagnation_iter=10, *args):\n",
    "    particles = [Particle(bounds) for _ in range(num_particles)]\n",
    "    global_best_position = particles[0].position.copy()\n",
    "    global_best_score = float('inf')\n",
    "    no_improvement_count = 0\n",
    "\n",
    "    for iter in range(max_iter):\n",
    "        for particle in particles:\n",
    "            score = func(particle.position[0], *args)\n",
    "            if score < particle.best_score:\n",
    "                particle.best_score = score\n",
    "                particle.best_position = particle.position.copy()\n",
    "            if score < global_best_score:\n",
    "                global_best_score = score\n",
    "                global_best_position = particle.position.copy()\n",
    "                no_improvement_count = 0  # Reset the stagnation counter\n",
    "            else:\n",
    "                no_improvement_count += 1\n",
    "\n",
    "        if no_improvement_count >= stagnation_iter:\n",
    "            #print(f\"No improvement for {stagnation_iter} iterations, stopping early.\")\n",
    "            break\n",
    "\n",
    "        if global_best_score < tol:\n",
    "            #print(f\"Global best score {global_best_score} reached tolerance {tol}, stopping early.\")\n",
    "            break\n",
    "\n",
    "        for particle in particles:\n",
    "            particle.update_velocity(global_best_position, w, c1, c2)\n",
    "            particle.update_position(bounds)\n",
    "\n",
    "        #print(f\"Iteration {iter+1}/{max_iter}, Global Best Score: {global_best_score}\")\n",
    "\n",
    "    return global_best_position, global_best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./examples/cython/check_pso.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./examples/cython/check_pso.py\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from heat_treatment import get_T_and_D\n",
    "from pso_python import pso\n",
    "\n",
    "\n",
    "# Calculate fraction of GB sites compared to all sites in the system\n",
    "def gb_site_fraction(R_G=100e-6, gb_width=8.4e-10):\n",
    "    V_G = R_G**3\n",
    "    V_GB = V_G - (R_G - gb_width)**3\n",
    "    return V_GB/V_G\n",
    "\n",
    "def obj_func(lamda, E, Rg_T, fi, x_hat_sum):\n",
    "        nom = np.exp( -(E - lamda) / Rg_T)\n",
    "        nom = np.clip(nom, a_min=None, a_max=1e300)  \n",
    "\n",
    "        denom = 1 + np.exp( -(E - lamda) / Rg_T)\n",
    "\n",
    "        xk_i_hat_temp = nom/denom \n",
    "        xk_hat_temp = fi * xk_i_hat_temp \n",
    "\n",
    "        \n",
    "        abs_difference = np.abs(xk_hat_temp - x_hat_sum) \n",
    "        return abs_difference\n",
    "\n",
    "def kinetics_python(t_tot: int, dt: float, accuracy: float, Tstart: float, R_G: float, D0: float, dQ: float,\n",
    "                  x_bulk: float, GB_thickness: float, E: float, A: float, gb_conc: float, Tend=None, r=None, heat_treatment_type=\"linear\"):\n",
    "    \n",
    "    \n",
    "    R_g = (8.314 / (1.602 * 10 ** (-19))) / (6.022 * 10 ** (23))  # gas constant in eV/K --> Boltzmann constant\n",
    "\n",
    "    temperatures, diffusion_coefficients = get_T_and_D(t_tot=t_tot, Tstart=Tstart, D0=D0, dQ=dQ, dt=dt, Tend=Tend, heat_treatment_type=heat_treatment_type, r=r)\n",
    "    Rg_Ts = temperatures * R_g\n",
    "\n",
    "    gb_concs = np.empty(shape=(len(temperatures), 1), dtype=np.float32)\n",
    "    ife = np.empty(shape=(len(temperatures), 1), dtype=np.float32)\n",
    "    \n",
    "    # Model specific parameters\n",
    "    m = 1\n",
    "    N_tot = 1\n",
    "    f = gb_site_fraction(R_G=R_G, gb_width=GB_thickness) \n",
    "    fi = f * m/N_tot\n",
    "    fg = fi / f \n",
    "    x_hat_ki = gb_conc \n",
    "    x_global = (1 - f) * x_bulk + fi * x_hat_ki\n",
    "    x_hat_sum = fi * x_hat_ki\n",
    "    x_bulk_start = x_bulk \n",
    "\n",
    "\n",
    "    # Starting value for optimization\n",
    "    #lamda = 0.001\n",
    "\n",
    "    for indx in range(len(temperatures)):\n",
    "\n",
    "        Rg_T = Rg_Ts[indx]\n",
    "        \n",
    "        D = diffusion_coefficients[indx]\n",
    "        \n",
    "        # Perform minimization\n",
    "       \n",
    "        #print(lamda)\n",
    "        # Optimization using PSO\n",
    "        result = pso(obj_func, [(-3, 3)], 30, 100, 0.5, 1.0, 2.0, 1e-6, 50, E, Rg_T, fi, x_hat_sum)\n",
    "        new_lamda = result[0]\n",
    "        lamda = new_lamda\n",
    "        result_value = result[1]\n",
    "        \n",
    "        \n",
    "        \n",
    "        nom = np.exp( -(E - lamda) / Rg_T)\n",
    "        nom = np.clip(nom, a_min=None, a_max=1e300)  \n",
    "\n",
    "        denom = 1 + np.exp( -(E - lamda) / Rg_T)\n",
    "\n",
    "        x_hat_ki = nom/denom\n",
    "        \n",
    "        gb_concs[indx] = x_hat_ki * fg\n",
    "        \n",
    "\n",
    "        nom_ln = 1 - x_bulk\n",
    "        denom_ln = x_bulk\n",
    "        frac_ln = np.log(nom_ln/denom_ln)\n",
    "\n",
    "        lamda_frac = lamda/Rg_T\n",
    "\n",
    "        lhs = 15*x_bulk*D/(R_G**2)\n",
    "\n",
    "        dx_hat = (-frac_ln - lamda_frac) * lhs \n",
    "\n",
    "        if np.isnan(dx_hat).any():\n",
    "                    raise ValueError(\"NaN value encountered in rhs. Stopping calculation.\")\n",
    "\n",
    "        x_hat_sum = x_hat_sum + dx_hat * dt\n",
    "    \n",
    "        \n",
    "        x_bulk = (x_global - x_hat_sum) / (1-f)\n",
    "\n",
    "        ife[indx] = (x_hat_sum * fg - x_bulk_start)/A\n",
    "        \n",
    "    return gb_concs, ife\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./examples/cython/execute_check_kinetics_pso.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./examples/cython/execute_check_kinetics_pso.py\n",
    "from timeit import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "from check_pso import kinetics_python\n",
    "# Define the parameters\n",
    "params = {\n",
    "    't_tot': 3600,\n",
    "    'dt': 0.1,\n",
    "    'accuracy': 1e-6,\n",
    "    'Tstart': 2000.0,\n",
    "    'R_G': 100e-6,\n",
    "    'dQ': 2.355,\n",
    "    'D0': 3.3e-5,\n",
    "    'x_bulk': 0.0004942285667828602,\n",
    "    'GB_thickness': 8.4e-10,\n",
    "    'E': -1.2972039599999334,\n",
    "    'A': 0.27920385353982713,\n",
    "    'gb_conc': 0.47854028493419043,\n",
    "    'Tend': 500.0,\n",
    "    'heat_treatment_type': 'linear',\n",
    "    'r': -1.0\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "results = kinetics_python(**params)\n",
    "\n",
    "plt.plot(results[0])\n",
    "plt.savefig(\"check_pso.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ./examples/cython/execute_check_kinetics_pso.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./examples/cython/pso_cython.pyx\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./examples/cython/pso_cython.pyx\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from libc.math cimport exp, sqrt\n",
    "\n",
    "class Particle:\n",
    "    def __init__(self, list bounds):\n",
    "        self.position = np.array([np.random.uniform(low, high) for low, high in bounds])\n",
    "        self.velocity = np.array([np.random.uniform(-abs(high - low), abs(high - low)) for low, high in bounds])\n",
    "        self.best_position = self.position.copy()\n",
    "        self.best_score = float('inf')\n",
    "\n",
    "    def update_velocity(self, np.ndarray[np.double_t, ndim=1] global_best_position, double w, double c1, double c2):\n",
    "        cdef double r1, r2\n",
    "        r1, r2 = np.random.random(2)\n",
    "        cognitive = c1 * r1 * (self.best_position - self.position)\n",
    "        social = c2 * r2 * (global_best_position - self.position)\n",
    "        self.velocity = w * self.velocity + cognitive + social\n",
    "\n",
    "    def update_position(self, list bounds):\n",
    "        self.position += self.velocity\n",
    "        cdef int i\n",
    "        for i in range(len(bounds)):\n",
    "            self.position[i] = max(min(self.position[i], bounds[i][1]), bounds[i][0])\n",
    "\n",
    "cdef tuple pso_cython(func, list bounds, double Rg_T, double x_hat_sum, double fi, double E, int num_particles=30, int max_iter=100, double w=0.5, double c1=1.0, double c2=2.0, double tol=1e-6, int stagnation_iter=10):\n",
    "    cdef list particles = [Particle(bounds) for _ in range(num_particles)]\n",
    "    cdef np.ndarray[np.double_t, ndim=1] global_best_position = particles[0].position.copy()\n",
    "    cdef double global_best_score = float('inf')\n",
    "    cdef int no_improvement_count = 0\n",
    "\n",
    "    cdef int iter\n",
    "    for iter in range(max_iter):\n",
    "        for particle in particles:\n",
    "            score = func(particle.position, Rg_T, x_hat_sum, fi, E)\n",
    "            if score < particle.best_score:\n",
    "                particle.best_score = score\n",
    "                particle.best_position = particle.position.copy()\n",
    "            if score < global_best_score:\n",
    "                global_best_score = score\n",
    "                global_best_position = particle.position.copy()\n",
    "                no_improvement_count = 0  # Reset the stagnation counter\n",
    "            else:\n",
    "                no_improvement_count += 1\n",
    "\n",
    "        if no_improvement_count >= stagnation_iter:\n",
    "            break\n",
    "\n",
    "        if global_best_score < tol:\n",
    "            break\n",
    "\n",
    "        for particle in particles:\n",
    "            particle.update_velocity(global_best_position, w, c1, c2)\n",
    "            particle.update_position(bounds)\n",
    "\n",
    "    return global_best_position, global_best_score\n",
    "\n",
    "cdef double[:] isothermal(float Tstart, int t_tot, float dt):\n",
    "    cdef int n = int(t_tot / dt) + 1\n",
    "    cdef double[:] temperatures = np.zeros(n, dtype=np.float32)\n",
    "    cdef int i\n",
    "    for i in range(n):\n",
    "        temperatures[i] = Tstart\n",
    "    return temperatures\n",
    "\n",
    "cdef double[:] linear_heat_treatment(float Tstart, float Tend, int t_tot, float dt):\n",
    "    cdef int n = int(t_tot / dt) + 1\n",
    "    cdef double[:] temperatures = np.zeros(n, dtype=np.float64)\n",
    "    cdef float slope = (Tend - Tstart) / t_tot\n",
    "    cdef int i\n",
    "    for i in range(n):\n",
    "        temperatures[i] = Tstart + slope * (i * dt)\n",
    "    return temperatures\n",
    "\n",
    "cdef double[:] newton_cooling(float Tstart, float Tend, int t_tot, float dt, float r):\n",
    "    cdef int n = int(t_tot / dt) + 1\n",
    "    cdef double[:] temperatures = np.zeros(n, dtype=np.float32)\n",
    "    cdef int i\n",
    "    for i in range(n):\n",
    "        temperatures[i] = Tend + (Tstart - Tend) * exp(-r * sqrt(i * dt))\n",
    "    return temperatures\n",
    "\n",
    "cdef double[:] diff_coef(float D0, float dQ, double[:] T, float kB):\n",
    "    cdef int n = T.shape[0]\n",
    "    cdef double[:] diffusion_coefficients = np.zeros(n, dtype=np.float64)\n",
    "    cdef int i\n",
    "    for i in range(n):\n",
    "        diffusion_coefficients[i] = D0 * exp(-dQ / (kB * T[i]))\n",
    "    return diffusion_coefficients\n",
    "\n",
    "cpdef tuple get_T_and_D(int t_tot, float Tstart, float D0, float dQ, float dt, float Tend=-1, str heat_treatment_type=\"iso\", float r=-1):\n",
    "    cdef double[:] temperatures, diffusion_coefficients\n",
    "    if heat_treatment_type == \"iso\":\n",
    "        temperatures = isothermal(Tstart=Tstart, t_tot=t_tot, dt=dt)\n",
    "    elif heat_treatment_type == \"linear\":\n",
    "        if Tend == -1:\n",
    "            raise ValueError(\"Tend must be provided for linear heat treatment.\")\n",
    "        temperatures = linear_heat_treatment(Tstart=Tstart, Tend=Tend, t_tot=t_tot, dt=dt)\n",
    "    elif heat_treatment_type == \"newton_cooling\":\n",
    "        if Tend == -1 or r == -1:\n",
    "            raise ValueError(\"Tend and r must be provided for Newton cooling heat treatment.\")\n",
    "        temperatures = newton_cooling(Tstart=Tstart, Tend=Tend, t_tot=t_tot, dt=dt, r=r)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid heat_treatment_type. Must be 'iso', 'linear', or 'newton_cooling'.\")\n",
    "\n",
    "    diffusion_coefficients = diff_coef(D0=D0, dQ=dQ, T=temperatures, kB=(8.314 / (1.602 * 10**(-19))) / (6.022 * 10**(23)))\n",
    "\n",
    "    return temperatures, diffusion_coefficients\n",
    "\n",
    "cdef double gb_site_fraction(double R_G=100e-6, double gb_width=8.4e-10):\n",
    "    cdef double V_G = R_G**3\n",
    "    cdef double V_GB = V_G - (R_G - gb_width)**3\n",
    "    return V_GB / V_G\n",
    "\n",
    "cdef double obj_func(double[:] lamda, double Rg_T, double x_hat_sum, double fi, double E):\n",
    "    cdef double nom = exp(-(E - lamda[0]) / Rg_T)\n",
    "    nom = min(nom, 1e300)  \n",
    "    cdef double denom = 1 + exp(-(E - lamda[0]) / Rg_T)\n",
    "    cdef double xk_i_hat_temp = nom / denom\n",
    "    cdef double xk_hat_temp = fi * xk_i_hat_temp\n",
    "    return abs(xk_hat_temp - x_hat_sum)\n",
    "\n",
    "cdef double wrapped_obj_func(double[:] lamda, double Rg_T, double x_hat_sum, double fi, double E):\n",
    "    return obj_func(lamda, Rg_T, x_hat_sum, fi, E)\n",
    "\n",
    "cpdef tuple kinetics_cythonized_pso(int t_tot, double dt, double Tstart, double R_G, double D0, double dQ,\n",
    "                                   double x_bulk, double GB_thickness, double E, double A, double gb_conc,\n",
    "                                   double Tend=-1, double r=-1, str heat_treatment_type=\"linear\", int num_particles=30, \n",
    "                                   int max_iter=100, float w=0.5, float c1=1.0, float c2=2.0, float tol=1e-6, int stagnation_iter=10):\n",
    "    \n",
    "    cdef double R_g = (8.314 / (1.602 * 10 ** (-19))) / (6.022 * 10 ** (23))\n",
    "\n",
    "    cdef double[:] temperatures, diffusion_coefficients, gb_concs, ife\n",
    "    temperatures, diffusion_coefficients = get_T_and_D(t_tot, Tstart, D0, dQ, dt, Tend, heat_treatment_type, r)\n",
    "\n",
    "    cdef int len_temp = temperatures.shape[0]\n",
    "    gb_concs = np.empty(len_temp, dtype=np.float64)\n",
    "    ife = np.empty(len_temp, dtype=np.float64)\n",
    "\n",
    "    cdef double[:] Rg_Ts = np.array(temperatures) * R_g\n",
    "    cdef double[:] diff_coefs = diffusion_coefficients\n",
    "\n",
    "    cdef double m = 1\n",
    "    cdef double N_tot = 1\n",
    "    cdef double f = gb_site_fraction(R_G, GB_thickness)\n",
    "    cdef double fi = f * m / N_tot\n",
    "    cdef double fg = fi / f\n",
    "    cdef double x_hat_ki = gb_conc\n",
    "    cdef double x_global = (1 - f) * x_bulk + fi * x_hat_ki\n",
    "    cdef double x_hat_sum = fi * x_hat_ki\n",
    "    cdef double x_bulk_start = x_bulk\n",
    "\n",
    "    cdef double[:] lamda = np.array([0.001], dtype=np.float64)\n",
    "    cdef double[:] new_lamda\n",
    "\n",
    "    cdef int indx\n",
    "    cdef double Rg_T, D, result_value, nom, denom, nom_ln, denom_ln, frac_ln, lamda_frac, lhs, dx_hat\n",
    "\n",
    "    for indx in range(len_temp):\n",
    "        Rg_T = Rg_Ts[indx]\n",
    "        D = diff_coefs[indx]\n",
    "\n",
    "        # Use wrapped_obj_func instead of lambda\n",
    "        result = pso_cython(wrapped_obj_func, [(-3, 3)], Rg_T, x_hat_sum, fi, E, num_particles, max_iter, w, c1, c2, tol, stagnation_iter)\n",
    "        new_lamda = result[0]\n",
    "        lamda = new_lamda\n",
    "        result_value = result[-1]  # This value is not used, consider removing it if unnecessary\n",
    "\n",
    "        nom = exp(-(E - lamda[0]) / Rg_T)\n",
    "        nom = max(nom, 1e-300)  # Use max instead of np.clip for Cython\n",
    "        denom = 1 + exp(-(E - lamda[0]) / Rg_T)\n",
    "        x_hat_ki = nom / denom\n",
    "        gb_concs[indx] = x_hat_ki * fg\n",
    "\n",
    "        nom_ln = 1 - x_bulk\n",
    "        denom_ln = x_bulk\n",
    "        frac_ln = np.log(nom_ln / denom_ln)\n",
    "        lamda_frac = lamda[0] / Rg_T\n",
    "        lhs = 15 * x_bulk * D / (R_G**2)\n",
    "        dx_hat = (-frac_ln - lamda_frac) * lhs\n",
    "\n",
    "        if np.isnan(dx_hat).any():\n",
    "            raise ValueError(\"NaN value encountered in dx_hat. Stopping calculation.\")\n",
    "\n",
    "        x_hat_sum += dx_hat * dt\n",
    "        x_bulk = (x_global - x_hat_sum) / (1 - f)\n",
    "        ife[indx] = (x_hat_sum * fg - x_bulk_start) / A\n",
    "\n",
    "    return gb_concs, ife\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./examples/cython/setup_kinetics_pso.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./examples/cython/setup_kinetics_pso.py\n",
    "from Cython.Build import cythonize\n",
    "from setuptools import setup, Extension\n",
    "import numpy as np\n",
    "\n",
    "extensions = [\n",
    "    Extension(\n",
    "        \"kinetics_cythonized_pso\",\n",
    "        [\"./examples/cython/pso_cython.pyx\"],\n",
    "        include_dirs=[np.get_include()],  # Include the NumPy headers\n",
    "    )\n",
    "]\n",
    "\n",
    "setup(\n",
    "    ext_modules=cythonize(\n",
    "        extensions,\n",
    "        compiler_directives={'language_level': \"3\"}  # Ensure Cython uses Python 3 syntax\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling ./examples/cython/pso_cython.pyx because it changed.\n",
      "[1/1] Cythonizing ./examples/cython/pso_cython.pyx\n",
      "running build_ext\n",
      "building 'kinetics_cythonized_pso' extension\n",
      "gcc -pthread -B /home/amin/anaconda3/envs/pycalphad/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/amin/anaconda3/envs/pycalphad/include -fPIC -O2 -isystem /home/amin/anaconda3/envs/pycalphad/include -fPIC -I/home/amin/anaconda3/envs/pycalphad/lib/python3.11/site-packages/numpy/core/include -I/home/amin/anaconda3/envs/pycalphad/include/python3.11 -c ./examples/cython/pso_cython.c -o build/temp.linux-x86_64-cpython-311/./examples/cython/pso_cython.o\n",
      "In file included from \u001b[01m\u001b[K/home/amin/anaconda3/envs/pycalphad/lib/python3.11/site-packages/numpy/core/include/numpy/ndarraytypes.h:1929\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/amin/anaconda3/envs/pycalphad/lib/python3.11/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/amin/anaconda3/envs/pycalphad/lib/python3.11/site-packages/numpy/core/include/numpy/arrayobject.h:5\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./examples/cython/pso_cython.c:1249\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/amin/anaconda3/envs/pycalphad/lib/python3.11/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wcpp\u0007-Wcpp\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
      "gcc -pthread -B /home/amin/anaconda3/envs/pycalphad/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/home/amin/anaconda3/envs/pycalphad/lib -Wl,-rpath-link,/home/amin/anaconda3/envs/pycalphad/lib -L/home/amin/anaconda3/envs/pycalphad/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/home/amin/anaconda3/envs/pycalphad/lib -Wl,-rpath-link,/home/amin/anaconda3/envs/pycalphad/lib -L/home/amin/anaconda3/envs/pycalphad/lib build/temp.linux-x86_64-cpython-311/./examples/cython/pso_cython.o -o ./examples/cython/kinetics_cythonized_pso.cpython-311-x86_64-linux-gnu.so\n"
     ]
    }
   ],
   "source": [
    "!python3 ./examples/cython/setup_kinetics_pso.py build_ext -b ./examples/cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./examples/cython/execute_kinetics_pso.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./examples/cython/execute_kinetics_pso.py\n",
    "from timeit import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the parameters\n",
    "params = {\n",
    "    't_tot': 3600,\n",
    "    'dt': 0.1,\n",
    "    'accuracy': 1e-6,\n",
    "    'Tstart': 2000.0,\n",
    "    'R_G': 100e-6,\n",
    "    'dQ': 2.355,\n",
    "    'D0': 3.3e-5,\n",
    "    'x_bulk': 0.0004942285667828602,\n",
    "    'GB_thickness': 8.4e-10,\n",
    "    'E': -1.2972039599999334,\n",
    "    'A': 0.27920385353982713,\n",
    "    'gb_conc': 0.47854028493419043,\n",
    "    'Tend': 500.0,\n",
    "    'heat_treatment_type': 'linear',\n",
    "    'r': -1.0\n",
    "}\n",
    "\n",
    "params_pso = {\n",
    "    't_tot': 3600,\n",
    "    'dt': 0.1,\n",
    "    'Tstart': 2000.0,\n",
    "    'R_G': 100e-6,\n",
    "    'dQ': 2.355,\n",
    "    'D0': 3.3e-5,\n",
    "    'x_bulk': 0.0004942285667828602,\n",
    "    'GB_thickness': 8.4e-10,\n",
    "    'E': -1.2972039599999334,\n",
    "    'A': 0.27920385353982713,\n",
    "    'gb_conc': 0.47854028493419043,\n",
    "    'Tend': 500.0,\n",
    "    'heat_treatment_type': 'linear',\n",
    "    'r': -1.0\n",
    "}\n",
    "\n",
    "\n",
    "t1 = timeit(\"kinetics_python(**params)\",\n",
    "            setup=\"from kinetics_python import kinetics_python; from __main__ import params\",\n",
    "            number=1)\n",
    "\n",
    "t2 = timeit(\"kinetics_cythonized_nm(**params)\",\n",
    "            setup=\"from kinetics_cythonized_nm import kinetics_cythonized_nm; from __main__ import params\",\n",
    "            number=1)\n",
    "\n",
    "t3 = timeit(\"kinetics_cythonized_pso(**params_pso)\",\n",
    "            setup=\"from kinetics_cythonized_pso import kinetics_cythonized_pso; from __main__ import params_pso\",\n",
    "            number=1)\n",
    "\n",
    "\n",
    "print(f\"Python: Time for get kinetics: {t1} seconds for 1 run\")\n",
    "print(f\"Annotated: Time for get kinetics: {t2} seconds for 1 run\")\n",
    "print(f\"Cythonized: Time for get kinetics: {t3} seconds for 1 run\")\n",
    "print(f\"Cythonized code with self written Nelder-Mead is {t1/t2} times faster than the originial python implementation using the scipy Nelder-Mead minimizer.\")\n",
    "print(f\"Cythonized code with self written PSO is {t1/t3} times faster than the originial python implementation using the scipy Nelder-Mead minimizer.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: Time for get kinetics: 32.48031539200747 seconds for 1 run\n",
      "Annotated: Time for get kinetics: 3.521098520999658 seconds for 1 run\n",
      "Cythonized: Time for get kinetics: 7.529907082993304 seconds for 1 run\n",
      "Cythonized code with self written Nelder-Mead is 9.224483552021185 times faster than the originial python implementation using the scipy Nelder-Mead minimizer.\n",
      "Cythonized code with self written PSO is 4.313508126197997 times faster than the originial python implementation using the scipy Nelder-Mead minimizer.\n"
     ]
    }
   ],
   "source": [
    "!python3 ./examples/cython/execute_kinetics_pso.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./examples/cython/execute_comparison_kinetics_pso.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./examples/cython/execute_comparison_kinetics_pso.py\n",
    "from timeit import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "from kinetics_cythonized_nm import kinetics_cythonized_nm\n",
    "from kinetics_python import kinetics_python\n",
    "from kinetics_cythonized_pso import kinetics_cythonized_pso\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "params = {\n",
    "    't_tot': 3600,\n",
    "    'dt': 0.1,\n",
    "    'accuracy': 1e-6,\n",
    "    'Tstart': 2000.0,\n",
    "    'R_G': 100e-6,\n",
    "    'dQ': 2.355,\n",
    "    'D0': 3.3e-5,\n",
    "    'x_bulk': 0.0004942285667828602,\n",
    "    'GB_thickness': 8.4e-10,\n",
    "    'E': -1.2972039599999334,\n",
    "    'A': 0.27920385353982713,\n",
    "    'gb_conc': 0.47854028493419043,\n",
    "    'Tend': 500.0,\n",
    "    'heat_treatment_type': 'linear',\n",
    "    'r': -1.0\n",
    "}\n",
    "\n",
    "params_pso = {\n",
    "    't_tot': 3600,\n",
    "    'dt': 0.1,\n",
    "    'Tstart': 2000.0,\n",
    "    'R_G': 100e-6,\n",
    "    'dQ': 2.355,\n",
    "    'D0': 3.3e-5,\n",
    "    'x_bulk': 0.0004942285667828602,\n",
    "    'GB_thickness': 8.4e-10,\n",
    "    'E': -1.2972039599999334,\n",
    "    'A': 0.27920385353982713,\n",
    "    'gb_conc': 0.47854028493419043,\n",
    "    'Tend': 500.0,\n",
    "    'heat_treatment_type': 'linear',\n",
    "    'r': -1.0\n",
    "}\n",
    "\n",
    "            \n",
    "results_python = kinetics_python(**params)\n",
    "gb_cython_nm, ife_cython_nm = kinetics_cythonized_nm(**params)\n",
    "gb_cython_pso, ife_cython_pso = kinetics_cythonized_pso(**params_pso)\n",
    "\n",
    "\n",
    "plt.plot(results_python[0], color=\"red\",label=\"python\")\n",
    "plt.plot(np.array(gb_cython_nm), color=\"green\",ls=\"--\",label=\"cython\")\n",
    "plt.plot(np.array(gb_cython_pso), color=\"blue\",ls=\"-.\",label=\"cython\")\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"comparison_python_cython_pso.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ./examples/cython/execute_comparison_kinetics_pso.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is probably as good as we get with this method. Certainly, there may be a way to further optimize the cythonization of the above script. I was also not able to cythonize the Particle class, although there might be a way to do so. However, the code is still 4.5 $\\times$ faster than the original code. And hopefully, we can take the big advatange of the PSO over the Nelder-Mead and parallelize it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycalphad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
